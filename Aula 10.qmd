---
title: "Anova I fator, Teste de Normalidade e Homocedasticidade, Teste não-paramétrico"
format: html
---

## Anova I fator
A Análise de Variância, ou ANOVA, é uma análise estatística para determinar a contribuição de diferentes fatores na variância total de um experimento.

A análise de variância de I fator, ou ANOVA simples, é uniletaral. Adequada para experimentos com apenas uma variável independente com dois ou mais níveis.

Nessa etapa de aprendizagem, começamos a trabalhar algo que chamaremos de **Análise Exploratória**. Antes de determinar qualquer análise estatística no trabalho, é importante trabalhar uma análise visual. Essa análise já permite que algumas conclusões sejam feitas e que o caminho mais adequado seja escolhido. A análise exploratória permite quem está trabalhando os dados perceber se existe algum padrão de distribuição nos dados, se essa distribuição é, visualmente, normal, se os dados se agrupam de alguma forma, etc.

Então, o primeiro passo agora, é explodar os dados.

```{r}
library (readxl)
library (tidyverse)

micelial <- read_excel("dados-diversos.xlsx", "micelial")

micelial |> 
  ggplot(aes(especie, tcm))+
  geom_boxplot()
```

Feita essa análise visual, seja com boxplot, histogramas, colunas, dispersão... partimos para aplicação da Anova I fator.

```{r}
aov1 <- aov(tcm ~ especie, data = micelial)
summary (aov1)
```

## Testes de Normalidade e Homocedasticidade

### Teste de Normalidade
A suposição de normalidade dos dados amostrais é uma condição exigida para a realização de muitas inferências válidas a respeito de parâmetros populacionais. Vários dos diferentes métodos de estimação e testes de hipóteses existentes foram formulados sob a suposição de que a amostra aleatória tenha sido extraída de uma população gaussiana.

### Teste de Homocedasticidade
Em análise de variância(ANOVA), há um pressuposto que deve ser atendido que é de os erros terem variância comum, ou seja, homocedasticidade. Isso implica que cada tratamento que se está sendo comparado pelo teste F, deve ter aproximadamente a mesma variância para que a ANOVA tenha validade. Quando este pressuposto não é atendido dizemos que as variâncias não são homogêneas, ou ainda, que existe heterocedasticidade.

```{r}
#Checando as premissas

library (performance)

check_heteroscedasticity(aov1)
check_normality(aov1)

#Testes de Normalidade

hist(aov1$residuals) 
#Permite ver a curva de distribuição dos dados, confirmando o que se tem nos testes anteriores - distribuição normal.

shapiro.test(aov1$residuals)
```

Outra forma de verificar se uma amostra segue a distribuição gaussiana é através dos gráficos de envelope normal de probabilidade e seu envelope com intervalo de confiança simulado.

Podemos fazer usando as funções "qqnorm()" e "qqline" sem o envelope:

```{r}
qqnorm(aov1$residuals)
qqline(aov1$residuals)
```

Ou com o envelope simulado com o pacote "DHARMa" e a função "plot()":

```{r}
library (DHARMa)
plot(simulateResiduals(aov1))
```

É possível ainda encontrar casos como o exemplo abaixo:

```{r}
InsectSprays

insects <- as_tibble(InsectSprays) |> 
  select (spray, count)

insects |> 
  ggplot(aes(spray, count))+
  geom_boxplot()
```

Após a análise exploratória, é possível perceber que os dados apresentam uma distribuição um pouco diferente. Partimos para a aplicação de ANOVA e checar as premissas.

```{r}
aov2 <- aov(count ~ spray, data = insects)
summary (aov2)

check_heteroscedasticity(aov2)
check_normality(aov2)
```

Feito isso, vemos que os dados não apresentam distruibuição normal e são heterocedasticos. Uma das alternativas que temos para trabalhar esse conjunto é a transformação. Nesse caso, usaremos a transformação em raiz (sqrt), mas o R tem uma série de transformações possíveis. As transformações são feitas por tentativa e erro, até que uma delas atenda o que você precisa.

```{r}
aov3 <- aov(sqrt(count) ~ spray, data = insects)
summary (aov3)

check_heteroscedasticity(aov3)
check_normality(aov3)

#Os dados transformados por raiz são normais e homocedaticos.

#Testes de Normalidade

hist(aov3$residuals)
shapiro.test(aov3$residuals)

#Gráficos para distribuição gaussiana
qqnorm(aov3$residuals)
qqline(aov3$residuals)

```

### Pacote "emmeans"
Calcular médias marginais estimadas (EMMs) para fatores específicos ou combinações de fatores em um modelo linear; e opcionalmente, comparações ou contrastes entre eles. EMMs também são conhecidos como médias de mínimos quadrados.

```{r}
library (emmeans)

aov3_means <- emmeans(aov3, ~ spray,
                       type = "response")
aov3_means
pwpm(aov3_means)
```

### Pacote "multcomp" 
Testes simultâneos e intervalos de confiança para hipóteses lineares gerais em modelos paramétricos, incluindo efeitos lineares, lineares generalizados, lineares mistos e modelos de sobrevivência.

### Pacote "multcompView"
Converta um vetor lógico ou um vetor de valores-p ou uma matriz de correlação, diferença ou distância em uma exibição identificando os pares para os quais as diferenças não foram significativamente diferentes.

### cld
Extrai e exibe informações sobre todas as comparações pareadas de médias de mínimos quadrados.

```{r}
library (multcomp)
library (multcompView)
cld(aov3_means)
```

## Teste Não Paramétrico
Os testes não paramétricos, também conhecidos como testes de distribuição gratuita, são aqueles baseados em certas hipóteses, mas que não possuem uma organização normal. Geralmente, contêm resultados estatísticos provenientes de suas ordenações, o que os torna mais fáceis de entender.

### Teste de Kruskal-Wallis
O teste de Kruskal-Wallis é utilizado em situações onde queremos comparar mais de dois grupos independentes, de tamanhos iguais ou não, com variável resposta quantitativa. O teste é uma alternativa quando os pressupostos necesários pelo teste F da Análise de Variância não são atendidos, tendo em vista que o teste de Kruskal-Wallis dispensa a pressuposição de normalidade e homocedasticidade.

```{r}
kruskal.test(count ~spray, data = insects)

library (agricolae)

kruskal(insects$count, insects$spray,
        console = TRUE)

```

### glm
Usado para ajustar modelos lineares generalizados, especificados por meio de uma descrição simbólica do preditor linear e uma descrição da distribuição de erro.

### Família
Os objetos de família fornecem uma maneira conveniente de especificar os detalhes dos modelos usados por funções como "glm".

```{r}
glm1 <- glm(count ~ spray,
            data = insects,
            family = poisson(link = "identity"))
```

Visualização gráfica e comparação de médias.

```{r}
library (DHARMa)
plot(simulateResiduals(glm1))
summary(glm1)

glml_means <- emmeans(glm1, ~ spray)
cld(glml_means)
```

## Transformação BoxCox
A transformação Box-Cox é uma transformação de poder que elimina a não linearidade entre variáveis, variâncias diferentes e assimetria variável. A função boxcox do pacote MASS em R pode ser usada para estimar o parâmetro de transformação usando estimativa de máxima verossimilhança. Também receberemos o intervalo de confiança de 95% do parâmetro dessa função.Você deve calcular um modelo linear com a função lm e passá-lo para a função boxcox para determinar o “lambda” apropriado. 


```{r}
library (MASS)
insects
b <- boxcox (lm(insects$count+0.1 ~ 1))

lambda <- b$x[which.max(b$y)]
lambda

#A linha vertical tracejada no meio representa o parâmetro estimado lambda hat.

insects$count2 <- (insects$count ^ lambda - 1) / lambda
insects$count
```

