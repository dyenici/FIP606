[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula 10.html",
    "href": "Aula 10.html",
    "title": "Anova I fator, Teste de Normalidade e Homocedasticidade, Teste não-paramétrico",
    "section": "",
    "text": "A Análise de Variância, ou ANOVA, é uma análise estatística para determinar a contribuição de diferentes fatores na variância total de um experimento.\nA análise de variância de I fator, ou ANOVA simples, é uniletaral. Adequada para experimentos com apenas uma variável independente com dois ou mais níveis.\nNessa etapa de aprendizagem, começamos a trabalhar algo que chamaremos de Análise Exploratória. Antes de determinar qualquer análise estatística no trabalho, é importante trabalhar uma análise visual. Essa análise já permite que algumas conclusões sejam feitas e que o caminho mais adequado seja escolhido. A análise exploratória permite quem está trabalhando os dados perceber se existe algum padrão de distribuição nos dados, se essa distribuição é, visualmente, normal, se os dados se agrupam de alguma forma, etc.\nEntão, o primeiro passo agora, é explodar os dados.\n\nlibrary (readxl)\nlibrary (tidyverse)\n\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"micelial\")\n\nmicelial |> \n  ggplot(aes(especie, tcm))+\n  geom_boxplot()\n\n\n\n\nFeita essa análise visual, seja com boxplot, histogramas, colunas, dispersão… partimos para aplicação da Anova I fator.\n\naov1 <- aov(tcm ~ especie, data = micelial)\nsummary (aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nespecie      4 0.4692 0.11729   1.983  0.117\nResiduals   37 2.1885 0.05915"
  },
  {
    "objectID": "Aula 10.html#testes-de-normalidade-e-homocedasticidade",
    "href": "Aula 10.html#testes-de-normalidade-e-homocedasticidade",
    "title": "Anova I fator, Teste de Normalidade e Homocedasticidade, Teste não-paramétrico",
    "section": "Testes de Normalidade e Homocedasticidade",
    "text": "Testes de Normalidade e Homocedasticidade\n\nTeste de Normalidade\nA suposição de normalidade dos dados amostrais é uma condição exigida para a realização de muitas inferências válidas a respeito de parâmetros populacionais. Vários dos diferentes métodos de estimação e testes de hipóteses existentes foram formulados sob a suposição de que a amostra aleatória tenha sido extraída de uma população gaussiana.\n\n\nTeste de Homocedasticidade\nEm análise de variância(ANOVA), há um pressuposto que deve ser atendido que é de os erros terem variância comum, ou seja, homocedasticidade. Isso implica que cada tratamento que se está sendo comparado pelo teste F, deve ter aproximadamente a mesma variância para que a ANOVA tenha validade. Quando este pressuposto não é atendido dizemos que as variâncias não são homogêneas, ou ainda, que existe heterocedasticidade.\n\n#Checando as premissas\n\nlibrary (performance)\n\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.175).\n\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.074).\n\n#Testes de Normalidade\n\nhist(aov1$residuals) \n\n\n\n#Permite ver a curva de distribuição dos dados, confirmando o que se tem nos testes anteriores - distribuição normal.\n\nshapiro.test(aov1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  aov1$residuals\nW = 0.95101, p-value = 0.07022\n\n\nOutra forma de verificar se uma amostra segue a distribuição gaussiana é através dos gráficos de envelope normal de probabilidade e seu envelope com intervalo de confiança simulado.\nPodemos fazer usando as funções “qqnorm()” e “qqline” sem o envelope:\n\nqqnorm(aov1$residuals)\nqqline(aov1$residuals)\n\n\n\n\nOu com o envelope simulado com o pacote “DHARMa” e a função “plot()”:\n\nlibrary (DHARMa)\nplot(simulateResiduals(aov1))\n\n\n\n\nÉ possível ainda encontrar casos como o exemplo abaixo:\n\nInsectSprays\n\n   count spray\n1     10     A\n2      7     A\n3     20     A\n4     14     A\n5     14     A\n6     12     A\n7     10     A\n8     23     A\n9     17     A\n10    20     A\n11    14     A\n12    13     A\n13    11     B\n14    17     B\n15    21     B\n16    11     B\n17    16     B\n18    14     B\n19    17     B\n20    17     B\n21    19     B\n22    21     B\n23     7     B\n24    13     B\n25     0     C\n26     1     C\n27     7     C\n28     2     C\n29     3     C\n30     1     C\n31     2     C\n32     1     C\n33     3     C\n34     0     C\n35     1     C\n36     4     C\n37     3     D\n38     5     D\n39    12     D\n40     6     D\n41     4     D\n42     3     D\n43     5     D\n44     5     D\n45     5     D\n46     5     D\n47     2     D\n48     4     D\n49     3     E\n50     5     E\n51     3     E\n52     5     E\n53     3     E\n54     6     E\n55     1     E\n56     1     E\n57     3     E\n58     2     E\n59     6     E\n60     4     E\n61    11     F\n62     9     F\n63    15     F\n64    22     F\n65    15     F\n66    16     F\n67    13     F\n68    10     F\n69    26     F\n70    26     F\n71    24     F\n72    13     F\n\ninsects <- as_tibble(InsectSprays) |> \n  select (spray, count)\n\ninsects |> \n  ggplot(aes(spray, count))+\n  geom_boxplot()\n\n\n\n\nApós a análise exploratória, é possível perceber que os dados apresentam uma distribuição um pouco diferente. Partimos para a aplicação de ANOVA e checar as premissas.\n\naov2 <- aov(count ~ spray, data = insects)\nsummary (aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(aov2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\ncheck_normality(aov2)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\n\nFeito isso, vemos que os dados não apresentam distruibuição normal e são heterocedasticos. Uma das alternativas que temos para trabalhar esse conjunto é a transformação. Nesse caso, usaremos a transformação em raiz (sqrt), mas o R tem uma série de transformações possíveis. As transformações são feitas por tentativa e erro, até que uma delas atenda o que você precisa.\n\naov3 <- aov(sqrt(count) ~ spray, data = insects)\nsummary (aov3)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5  88.44  17.688    44.8 <2e-16 ***\nResiduals   66  26.06   0.395                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(aov3)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\ncheck_normality(aov3)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\n#Os dados transformados por raiz são normais e homocedaticos.\n\n#Testes de Normalidade\n\nhist(aov3$residuals)\n\n\n\nshapiro.test(aov3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  aov3$residuals\nW = 0.98721, p-value = 0.6814\n\n#Gráficos para distribuição gaussiana\nqqnorm(aov3$residuals)\nqqline(aov3$residuals)\n\n\n\n\n\n\nPacote “emmeans”\nCalcular médias marginais estimadas (EMMs) para fatores específicos ou combinações de fatores em um modelo linear; e opcionalmente, comparações ou contrastes entre eles. EMMs também são conhecidos como médias de mínimos quadrados.\n\nlibrary (emmeans)\n\naov3_means <- emmeans(aov3, ~ spray,\n                       type = \"response\")\naov3_means\n\n spray response    SE df lower.CL upper.CL\n A        14.14 1.364 66   11.550    17.00\n B        15.03 1.406 66   12.352    17.97\n C         1.55 0.452 66    0.779     2.58\n D         4.68 0.785 66    3.248     6.38\n E         3.27 0.656 66    2.095     4.72\n F        16.15 1.458 66   13.370    19.19\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \n\npwpm(aov3_means)\n\n        A       B       C       D       E       F\nA [14.14]  0.9975  <.0001  <.0001  <.0001  0.9145\nB  -0.116 [15.03]  <.0001  <.0001  <.0001  0.9936\nC   2.516   2.632 [ 1.55]  0.0081  0.2513  <.0001\nD   1.596   1.712  -0.919 [ 4.68]  0.7366  <.0001\nE   1.951   2.067  -0.565   0.355 [ 3.27]  <.0001\nF  -0.258  -0.142  -2.774  -1.854  -2.209 [16.15]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\n\nPacote “multcomp”\nTestes simultâneos e intervalos de confiança para hipóteses lineares gerais em modelos paramétricos, incluindo efeitos lineares, lineares generalizados, lineares mistos e modelos de sobrevivência.\n\n\nPacote “multcompView”\nConverta um vetor lógico ou um vetor de valores-p ou uma matriz de correlação, diferença ou distância em uma exibição identificando os pares para os quais as diferenças não foram significativamente diferentes.\n\n\ncld\nExtrai e exibe informações sobre todas as comparações pareadas de médias de mínimos quadrados.\n\nlibrary (multcomp)\nlibrary (multcompView)\ncld(aov3_means)\n\n spray response    SE df lower.CL upper.CL .group\n C         1.55 0.452 66    0.779     2.58  1    \n E         3.27 0.656 66    2.095     4.72  12   \n D         4.68 0.785 66    3.248     6.38   2   \n A        14.14 1.364 66   11.550    17.00    3  \n B        15.03 1.406 66   12.352    17.97    3  \n F        16.15 1.458 66   13.370    19.19    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula 10.html#teste-não-paramétrico",
    "href": "Aula 10.html#teste-não-paramétrico",
    "title": "Anova I fator, Teste de Normalidade e Homocedasticidade, Teste não-paramétrico",
    "section": "Teste Não Paramétrico",
    "text": "Teste Não Paramétrico\nOs testes não paramétricos, também conhecidos como testes de distribuição gratuita, são aqueles baseados em certas hipóteses, mas que não possuem uma organização normal. Geralmente, contêm resultados estatísticos provenientes de suas ordenações, o que os torna mais fáceis de entender.\n\nTeste de Kruskal-Wallis\nO teste de Kruskal-Wallis é utilizado em situações onde queremos comparar mais de dois grupos independentes, de tamanhos iguais ou não, com variável resposta quantitativa. O teste é uma alternativa quando os pressupostos necesários pelo teste F da Análise de Variância não são atendidos, tendo em vista que o teste de Kruskal-Wallis dispensa a pressuposição de normalidade e homocedasticidade.\n\nkruskal.test(count ~spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary (agricolae)\n\nkruskal(insects$count, insects$spray,\n        console = TRUE)\n\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c\n\n\n\n\nglm\nUsado para ajustar modelos lineares generalizados, especificados por meio de uma descrição simbólica do preditor linear e uma descrição da distribuição de erro.\n\n\nFamília\nOs objetos de família fornecem uma maneira conveniente de especificar os detalhes dos modelos usados por funções como “glm”.\n\nglm1 <- glm(count ~ spray,\n            data = insects,\n            family = poisson(link = \"identity\"))\n\nVisualização gráfica e comparação de médias.\n\nlibrary (DHARMa)\nplot(simulateResiduals(glm1))\n\n\n\nsummary(glm1)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson(link = \"identity\"), \n    data = insects)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3852  -0.8876  -0.1482   0.6063   2.6922  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  14.5000     1.0992  13.191  < 2e-16 ***\nsprayB        0.8333     1.5767   0.529    0.597    \nsprayC      -12.4167     1.1756 -10.562  < 2e-16 ***\nsprayD       -9.5833     1.2720  -7.534 4.92e-14 ***\nsprayE      -11.0000     1.2247  -8.981  < 2e-16 ***\nsprayF        2.1667     1.6116   1.344    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 3\n\nglml_means <- emmeans(glm1, ~ spray)\ncld(glml_means)\n\n spray emmean    SE  df asymp.LCL asymp.UCL .group\n C       2.08 0.417 Inf      1.27      2.90  1    \n E       3.50 0.540 Inf      2.44      4.56  12   \n D       4.92 0.640 Inf      3.66      6.17   2   \n A      14.50 1.099 Inf     12.35     16.65    3  \n B      15.33 1.130 Inf     13.12     17.55    3  \n F      16.67 1.179 Inf     14.36     18.98    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula 10.html#transformação-boxcox",
    "href": "Aula 10.html#transformação-boxcox",
    "title": "Anova I fator, Teste de Normalidade e Homocedasticidade, Teste não-paramétrico",
    "section": "Transformação BoxCox",
    "text": "Transformação BoxCox\nA transformação Box-Cox é uma transformação de poder que elimina a não linearidade entre variáveis, variâncias diferentes e assimetria variável. A função boxcox do pacote MASS em R pode ser usada para estimar o parâmetro de transformação usando estimativa de máxima verossimilhança. Também receberemos o intervalo de confiança de 95% do parâmetro dessa função.Você deve calcular um modelo linear com a função lm e passá-lo para a função boxcox para determinar o “lambda” apropriado.\n\nlibrary (MASS)\ninsects\n\n# A tibble: 72 × 2\n   spray count\n   <fct> <dbl>\n 1 A        10\n 2 A         7\n 3 A        20\n 4 A        14\n 5 A        14\n 6 A        12\n 7 A        10\n 8 A        23\n 9 A        17\n10 A        20\n# ℹ 62 more rows\n\nb <- boxcox (lm(insects$count+0.1 ~ 1))\n\n\n\nlambda <- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n#A linha vertical tracejada no meio representa o parâmetro estimado lambda hat.\n\ninsects$count2 <- (insects$count ^ lambda - 1) / lambda\ninsects$count\n\n [1] 10  7 20 14 14 12 10 23 17 20 14 13 11 17 21 11 16 14 17 17 19 21  7 13  0\n[26]  1  7  2  3  1  2  1  3  0  1  4  3  5 12  6  4  3  5  5  5  5  2  4  3  5\n[51]  3  5  3  6  1  1  3  2  6  4 11  9 15 22 15 16 13 10 26 26 24 13"
  },
  {
    "objectID": "Aula 11.html",
    "href": "Aula 11.html",
    "title": "ANOVA Fatorial",
    "section": "",
    "text": "ANOVA fatorial é usada quando há duas ou mais variáveis independentes. Cada um desses fatores pode ter vários níveis. ANOVA fatorial só pode ser usado no caso de um experimento fatorial completo, onde há uso de todas as permutações possíveis de fatores e seus níveis. Esta ANOVA não mede apenas a variável independente versus a independente, mas se os dois fatores afetam um ao outro.\n\n# Análise exploratória\n\nlibrary(readxl)\nlibrary(tidyverse)\n\ndat <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\n\ndat2 <- dat |> \n  mutate(inc = dis_sp/n_sp*100)\n\n# mutate()cria novas colunas que são funções de variáveis existentes. Essa função também pode modificar (se o nome for o mesmo de uma coluna existente) e excluir colunas (configurando seu valor como NULL).\n\ndat2 |> \n  ggplot(aes(x=treat,\n             y=inc)) +\n  geom_jitter(width = 0.1) +\n  facet_wrap(~ dose)\n\n\n\n\nAplicação de ANOVA\n\nm1 <- aov(inc ~ treat*dose,\n          data = dat2)\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ntreat        1  919.5   919.5   24.31 0.000151 ***\ndose         1  920.9   920.9   24.34 0.000150 ***\ntreat:dose   1  747.7   747.7   19.76 0.000407 ***\nResiduals   16  605.3    37.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.018).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\nOs dados não apresentam normalidade e homocedasticidade, partimos para a transformação.\n\nm2 <- aov(log(inc+0.5) ~ treat*dose,\n          data = dat2)\n\nlibrary(performance)\ncheck_normality(m2)\n\nWarning: Non-normality of residuals detected (p = 0.050).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.180).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n\n“Response”: trabalho com meus dados sem transformação.\n\n# Comparação de médias \"Tratamento em função da Dose\"\n\nlibrary(emmeans)\nmeans_m2 <- emmeans (m2, ~treat|dose,\n                     type=\"response\")\nmeans_m2\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL\n Ionic liquid    27.05 11.847 16   10.570    68.05\n Tebuconazole     1.21  0.737 16    0.188     3.76\n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL\n Ionic liquid     3.10  1.412 16    1.065     7.77\n Tebuconazole     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(means_m2)\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.21  0.737 16    0.188     3.76  1    \n Ionic liquid    27.05 11.847 16   10.570    68.05   2   \n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.42  0.925 16    0.194     4.83  1    \n Ionic liquid     3.10  1.412 16    1.065     7.77  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n# Comparação de médias \"Dose em função do Tratamento\"\n\nlibrary(emmeans)\nmeans_m2 <- emmeans (m2, ~dose|treat,\n                     type=\"response\")\nmeans_m2\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL\n  0.5    27.05 11.847 16   10.570    68.05\n  2.0     3.10  1.412 16    1.065     7.77\n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL\n  0.5     1.21  0.737 16    0.188     3.76\n  2.0     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(means_m2)\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL .group\n  2.0     3.10  1.412 16    1.065     7.77  1    \n  0.5    27.05 11.847 16   10.570    68.05   2   \n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL .group\n  0.5     1.21  0.737 16    0.188     3.76  1    \n  2.0     1.42  0.925 16    0.194     4.83  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nObtém o coeficiente de variação do experimento obtido pelos modelos lm() ou aov().\n\nlibrary(agricolae)\ncv.model(m2)\n\n[1] 65.04818\n\n\nOutro exemplo:\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"armazena\")\nmilho |> \n  filter(tempo==8) |> \n  ggplot(aes(factor(tipo),\n             peso_mil,\n             color=factor(umidade)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~umidade)\n\n\n\n\n\nmilho2 <- milho |> \n  filter(tempo==8)\n\nm2 <- aov(peso_mil~factor(tipo)\n          *factor(umidade), \n          data=milho2)\nsummary(m2)\n\n                             Df Sum Sq Mean Sq F value   Pr(>F)    \nfactor(tipo)                  1  11215   11215  2375.8 3.64e-15 ***\nfactor(umidade)               2  42814   21407  4534.8  < 2e-16 ***\nfactor(tipo):factor(umidade)  2   2329    1165   246.7 1.79e-10 ***\nResiduals                    12     57       5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmilho3 <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\nm4 <- aov(yield~hybrid*method,\n          data=milho3)\nsummary(m4)\n\n              Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid         5 105876446 21175289   8.312 2.66e-05 ***\nmethod         1     42951    42951   0.017    0.897    \nhybrid:method  5  10619453  2123891   0.834    0.534    \nResiduals     36  91709593  2547489                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\nEsta função apresenta resultados “emmeans” e comparações aos pares de forma compacta. Ele exibe uma matriz (ou matrizes) de estimativas, diferenças pareadas e valores de P.\n\nmilho3 <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\nm4 <- aov(yield~hybrid,\n          data=milho3)\nsummary(m4)\n\n            Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(m4)\n\nOK: Error variance appears to be homoscedastic (p = 0.763).\n\nmedias_m4 <- emmeans(m4,~hybrid)\nmedias_m4\n\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 552 42     9484    11712\n 30F53 YH   9309 552 42     8195    10423\n 30K64     11018 552 42     9904    12132\n 30S31H     8652 552 42     7538     9765\n 30S31YH    8056 552 42     6942     9170\n BG7049H   12402 552 42    11288    13516\n\nConfidence level used: 0.95 \n\ncld(medias_m4)\n\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 552 42     6942     9170  1    \n 30S31H     8652 552 42     7538     9765  12   \n 30F53 YH   9309 552 42     8195    10423  123  \n 30F53 HX  10598 552 42     9484    11712   234 \n 30K64     11018 552 42     9904    12132    34 \n BG7049H   12402 552 42    11288    13516     4 \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(medias_m4)\n\n         30F53 HX 30F53 YH   30K64  30S31H 30S31YH BG7049H\n30F53 HX  [10598]   0.5709  0.9942  0.1494  0.0254  0.2125\n30F53 YH     1288  [ 9309]  0.2643  0.9576  0.5999  0.0036\n30K64        -420    -1709 [11018]  0.0447  0.0059  0.4938\n30S31H       1946      658    2366 [ 8652]  0.9723  0.0003\n30S31YH      2541     1253    2962     595 [ 8056]  <.0001\nBG7049H     -1804    -3092   -1384   -3750   -4345 [12402]\n\nRow and column labels: hybrid\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(medias_m4)"
  },
  {
    "objectID": "Aula 12.html",
    "href": "Aula 12.html",
    "title": "ANOVA com bloco",
    "section": "",
    "text": "warning(FALSE)\n\nlibrary(readxl)\nlibrary(tidyverse)\n\nfungicidas <- read_excel(\"dados-diversos.xlsx\", \"fungicida_campo\")"
  },
  {
    "objectID": "Aula 12.html#delineamenrto-em-blocos-casualizado",
    "href": "Aula 12.html#delineamenrto-em-blocos-casualizado",
    "title": "ANOVA com bloco",
    "section": "Delineamenrto em Blocos Casualizado",
    "text": "Delineamenrto em Blocos Casualizado\nO delineamento em blocos casualizado (DBC) envolve os três princípios da experimentação: repetição, casualização e controle local. Neste caso, as condições locais não são homogêneas e podem ter efeito significativo sobre os tratamentos.\nCom o seguinte banco de dados é possível realizar a análise de variância (ANOVA) e testar as hipóteses sobre os tratamentos e blocos.\n\naov_fung <- aov(sev~trat+rep,data=\n                  fungicidas)\nsummary(aov_fung)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \ntrat         7   7135  1019.3 287.661 <2e-16 ***\nrep          1     19    18.6   5.239 0.0316 *  \nResiduals   23     81     3.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Mesmo sem significância, o bloco deve permanecer, pois o experimento foi montado em blocos.\n\nChecando as premissas e comparando as médias.\n\nlibrary(performance)\nlibrary(DHARMa)\n\ncheck_normality(aov_fung)\n\nOK: residuals appear as normally distributed (p = 0.230).\n\ncheck_heteroscedasticity(aov_fung)\n\nOK: Error variance appears to be homoscedastic (p = 0.484).\n\nplot(simulateResiduals(aov_fung))\n\n\n\nlibrary(emmeans)\n\nmeans_fung <- emmeans(aov_fung, ~trat)\nlibrary(multcomp)\nlibrary(multcompView)\n\ncld(means_fung)\n\n trat       emmean    SE df lower.CL upper.CL .group\n G            29.2 0.941 23     27.3     31.2  1    \n B            29.5 0.941 23     27.6     31.4  1    \n E            30.1 0.941 23     28.2     32.1  1    \n C            30.4 0.941 23     28.4     32.3  1    \n A            30.4 0.941 23     28.4     32.3  1    \n D            31.5 0.941 23     29.6     33.4  12   \n F            35.5 0.941 23     33.6     37.4   2   \n testemunha   75.8 0.941 23     73.8     77.7    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nplot(means_fung)+\n  coord_flip()+\n  theme_minimal()\n\n\n\n\n\nTrabalhando com parcela e subparcela\n\n#Os híbridos são minha parcela, o método minha subparcela.\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\naov_milho_bloco <- aov(index~factor(block)+hybrid*method+\n                         Error(factor(block)/hybrid/method), data=milho)\n\n# Método está dentro de híbrido, e os híbridos estão dentro do bloco.\n\nsummary(aov_milho_bloco)\n\n\nError: factor(block)\n              Df Sum Sq Mean Sq\nfactor(block)  3  592.2   197.4\n\nError: factor(block):hybrid\n          Df Sum Sq Mean Sq F value Pr(>F)  \nhybrid     5  974.2  194.84    3.14 0.0389 *\nResiduals 15  930.9   62.06                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: factor(block):hybrid:method\n              Df Sum Sq Mean Sq F value Pr(>F)  \nmethod         1  79.61   79.61   4.726 0.0433 *\nhybrid:method  5 265.28   53.06   3.150 0.0324 *\nResiduals     18 303.18   16.84                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Aula 12.html#atualizando-os-blocos-para-fatores",
    "href": "Aula 12.html#atualizando-os-blocos-para-fatores",
    "title": "ANOVA com bloco",
    "section": "Atualizando os blocos para fatores",
    "text": "Atualizando os blocos para fatores\n\nPacote “lme4”\nAjustar modelos de efeitos mistos lineares e lineares generalizados. Os modelos e seus componentes são representados usando classes e métodos S4.\n\n\nFunção “lmer”\nGerar um componente aleatório que é específico a cada indivíduo, de modo que podemos ter, para cada um, um intercepto e uma inclinação distintas.\n\nlibrary(lme4)\n\nmilho$block <- as.factor(milho$block)\nmix2 <- lmer(index~block+hybrid*method+\n               (1|block/hybrid), data=milho)\nanova(mix2)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nblock            3   5.376   1.792  0.1064\nhybrid           5 264.420  52.884  3.1397\nmethod           1  79.606  79.606  4.7262\nhybrid:method    5 265.281  53.056  3.1500\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.621).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n#anova com letra \"a\" não aparece p valor.\n\n\n#Anova com \"A\" é outra função - nessa aparece o p valor - associada ao pacote \"car\"\n\nmilho$block <- as.factor(milho$block)\nmix2 <- lmer(index~block+hybrid*method+\n               (1|block/hybrid), data=milho)\nlibrary(car)\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nblock          0.3192  3   0.956380   \nhybrid        15.6987  5   0.007759 **\nmethod         4.7262  1   0.029706 * \nhybrid:method 15.7498  5   0.007596 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.621).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\nmilho$block <- as.factor(milho$block)\nmix2 <- lmer(sqrt(index)~block+hybrid*method+\n               (1|block/hybrid), data=milho)\nlibrary(car)\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nblock          0.0764  3   0.994506   \nhybrid        15.4171  5   0.008721 **\nmethod         3.9239  1   0.047605 * \nhybrid:method 13.3025  5   0.020703 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.422).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.970).\n\n\n\nmeans_mix2 <- emmeans (mix2, ~hybrid|method)\nmeans_mix2\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL\n 30F53 HX   5.00 1.17 5356     2.69     7.30\n 30F53 YH   4.95 1.17 5356     2.65     7.25\n 30K64      4.50 1.17 5356     2.20     6.81\n 30S31H     6.10 1.17 5356     3.79     8.40\n 30S31YH    5.63 1.17 5356     3.33     7.93\n BG7049H    4.40 1.17 5356     2.10     6.71\n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL\n 30F53 HX   4.94 1.17 5356     2.64     7.25\n 30F53 YH   5.10 1.17 5356     2.80     7.41\n 30K64      4.61 1.17 5356     2.31     6.91\n 30S31H     5.13 1.17 5356     2.83     7.43\n 30S31YH    5.14 1.17 5356     2.84     7.44\n BG7049H    4.37 1.17 5356     2.07     6.67\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \n\ncld(means_mix2)\n\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    4.40 1.17 5356     2.10     6.71  1    \n 30K64      4.50 1.17 5356     2.20     6.81  1    \n 30F53 YH   4.95 1.17 5356     2.65     7.25  12   \n 30F53 HX   5.00 1.17 5356     2.69     7.30  12   \n 30S31YH    5.63 1.17 5356     3.33     7.93  12   \n 30S31H     6.10 1.17 5356     3.79     8.40   2   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    4.37 1.17 5356     2.07     6.67  1    \n 30K64      4.61 1.17 5356     2.31     6.91  1    \n 30F53 HX   4.94 1.17 5356     2.64     7.25  1    \n 30F53 YH   5.10 1.17 5356     2.80     7.41  1    \n 30S31H     5.13 1.17 5356     2.83     7.43  1    \n 30S31YH    5.14 1.17 5356     2.84     7.44  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nmeans_mix2 <- emmeans (mix2, ~method|hybrid)\nmeans_mix2\n\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL\n pin      5.00 1.17 5356     2.69     7.30\n silk     4.94 1.17 5356     2.64     7.25\n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL\n pin      4.95 1.17 5356     2.65     7.25\n silk     5.10 1.17 5356     2.80     7.41\n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL\n pin      4.50 1.17 5356     2.20     6.81\n silk     4.61 1.17 5356     2.31     6.91\n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL\n pin      6.10 1.17 5356     3.79     8.40\n silk     5.13 1.17 5356     2.83     7.43\n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL\n pin      5.63 1.17 5356     3.33     7.93\n silk     5.14 1.17 5356     2.84     7.44\n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL\n pin      4.40 1.17 5356     2.10     6.71\n silk     4.37 1.17 5356     2.07     6.67\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \n\ncld(means_mix2)\n\nhybrid = 30F53 HX:\n method emmean   SE   df lower.CL upper.CL .group\n silk     4.94 1.17 5356     2.64     7.25  1    \n pin      5.00 1.17 5356     2.69     7.30  1    \n\nhybrid = 30F53 YH:\n method emmean   SE   df lower.CL upper.CL .group\n pin      4.95 1.17 5356     2.65     7.25  1    \n silk     5.10 1.17 5356     2.80     7.41  1    \n\nhybrid = 30K64:\n method emmean   SE   df lower.CL upper.CL .group\n pin      4.50 1.17 5356     2.20     6.81  1    \n silk     4.61 1.17 5356     2.31     6.91  1    \n\nhybrid = 30S31H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     5.13 1.17 5356     2.83     7.43  1    \n pin      6.10 1.17 5356     3.79     8.40   2   \n\nhybrid = 30S31YH:\n method emmean   SE   df lower.CL upper.CL .group\n silk     5.14 1.17 5356     2.84     7.44  1    \n pin      5.63 1.17 5356     3.33     7.93  1    \n\nhybrid = BG7049H:\n method emmean   SE   df lower.CL upper.CL .group\n silk     4.37 1.17 5356     2.07     6.67  1    \n pin      4.40 1.17 5356     2.10     6.71  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula 13.html",
    "href": "Aula 13.html",
    "title": "Análise de Regressão",
    "section": "",
    "text": "Análise de regressão é uma técnica estatística utilizada para investigar a relação existente entre variáveis através da construção de uma equação (um modelo). De maneira geral, essa técnica pode ser utilizada com vários objetivos, dentre os quais se pode destacar: descrever a relação entre variáveis para entender um processo ou fenômeno; prever o valor de uma variável a partir do conhecimento dos valores das outras variáveis; substituir a medição de uma variável pela observação dos valores de outras variáveis; controlar os valores de uma variável em uma faixa de interesse.\n\n\nSlope (inclinação) diferente do ângulo 0.\n\n\n\nPara variáveis categóricas/comparação.\n\nwarning(FALSE)\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nestande <- read_excel(\"dados-diversos.xlsx\",\"estande\")\n\nestande |> ggplot (aes(trat,nplants))+\n  geom_point()+\n  facet_wrap(~exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se=F, method=\"lm\")\n\n\n\n\n\n#EXPERIMENTO 1\n\nexp1<-estande |> filter (exp==1)\nm1<-lm(nplants~trat,data=exp1)\nsummary(m1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\ng1 <- exp1 |> \n  ggplot(aes(trat,nplants))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  annotate(geom=\"text\",x=24,\n           y=70,label=\"y=52,5-0,24x\")\n\n\n#EXPERIMENTO 2\n\nexp2<-estande |> filter (exp==2)\nm2<-lm(nplants~trat,data=exp2)\nsummary(m2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\ng2 <- exp2 |> \n  ggplot(aes(trat,nplants))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  annotate(geom=\"text\",x=24,\n           y=70,label=\"y=60,9-0,7x\")\n\n\n#EXPERIMENTO 3\n\nexp3<-estande |> filter (exp==3)\nm3<-lm(nplants~trat,data=exp3)\nsummary(m3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\ng3 <- exp3 |> \n  ggplot(aes(trat,nplants))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  annotate(geom=\"text\",x=24,\n           y=70,label=\"y=95,75-0,76x\")\n\n\nlibrary(patchwork)\n\ng1|g2|g3"
  },
  {
    "objectID": "Aula 14.html",
    "href": "Aula 14.html",
    "title": "Regressão Linear",
    "section": "",
    "text": "A regressão linear é uma técnica de análise de dados que prevê o valor de dados desconhecidos usando outro valor de dados relacionado e conhecido. Ele modela matematicamente a variável desconhecida ou dependente e a variável conhecida ou independente como uma equação linear.\n\nwarning(FALSE)\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nestande <- read_excel(\"dados-diversos.xlsx\",\"estande\")\n\nestande |> ggplot (aes(trat,nplants))+\n  geom_point()+\n  facet_wrap(~exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se=F)\n\n\n\n\n\n\n\nestande2 <- estande |> \n  filter(exp ==2) |> \n  group_by(trat) |> \n  summarise(mean_nplants =\n              mean(nplants))\n\nestande2 |> ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n  #geom_line()+\n  geom_smooth(se = F,formula = y ~ poly(x,2), method = \"lm\")+\n  annotate (geom =\"text\",\n           x=25, y=70,\n           label= \"y=66.3 - 1.777x + //////0.0222x\n           R² = 0.88\")\n\n\n\n#R² - coeficiente de determinação (regressão linear)\n\n\n\n\nPermite que você teste o quão bem seu modelo se ajusta ao conjunto de dados sem sobreajustá-lo. A pontuação AIC recompensa os modelos que atingem uma alta pontuação de qualidade de ajuste e os penaliza se eles se tornarem excessivamente complexos. Por si só, a pontuação AIC não é muito útil, a menos que seja comparada com a pontuação AIC de um modelo concorrente. Espera-se que o modelo com a pontuação AIC mais baixa atinja um equilíbrio superior entre sua capacidade de ajustar o conjunto de dados e sua capacidade de evitar o ajuste excessivo do conjunto de dados.\n\nestande2 <- estande2 |> \n  mutate(trat2=trat^2)\n\nm1 <- lm(mean_nplants ~ trat,\n         data=estande2)\nsummary(m1)\n\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\nhist(m1$residuals)\n\n\n\nm2 <- lm(mean_nplants ~trat + trat2,\n         data = estande2)\nsummary(m2)\n\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n      1       2       3       4       5       6 \n 7.4484 -4.4200 -6.4386  1.0739  3.0474 -0.7111 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.70800  14.083 0.000776 ***\ntrat        -1.77720    0.62263  -2.854 0.064878 .  \ntrat2        0.02223    0.01242   1.790 0.171344    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.517 on 3 degrees of freedom\nMultiple R-squared:  0.8801,    Adjusted R-squared:  0.8001 \nF-statistic: 11.01 on 2 and 3 DF,  p-value: 0.04152\n\nAIC(m1,m2)\n\n   df      AIC\nm1  3 45.72200\nm2  4 43.36151"
  },
  {
    "objectID": "Aula 14.html#duas-variáveis-resposta",
    "href": "Aula 14.html#duas-variáveis-resposta",
    "title": "Regressão Linear",
    "section": "Duas variáveis resposta",
    "text": "Duas variáveis resposta\nA relação é com duas variáveis respostas - teste de associação; Análise de correlação - coeficiente de correlação (coef. de Pearson); R é sempre maior que R².\n\nCoeficiente de Pearson\nO coeficiente de correlação de Pearson é um teste que mede a relação estatística entre duas variáveis contínuas. Se a associação entre os elementos não for linear, o coeficiente não será representado adequadamente.\n\nmofo<- read_excel(\"dados-diversos.xlsx\", \"mofo\")\n\nmofo |>\n  ggplot(aes(inc, yld))+\n  geom_point()+\n  geom_smooth(se=F, method= \"lm\")+\n  facet_wrap(~study)\n\n\n\n\n\n\ncor.test\nEsta função realiza um teste de correlação entre duas variáveis.\n\n#Experimento 1\n\nmofo1 <- mofo |> \n  filter (study ==1)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1    76  2194  2265\n 2     1     2    53  1663  2618\n 3     1     3    42  1313  2554\n 4     1     4    37  1177  2632\n 5     1     5    29   753  2820\n 6     1     6    42  1343  2799\n 7     1     7    55  1519  2503\n 8     1     8    40   516  2967\n 9     1     9    26   643  2965\n10     1    10    18   400  3088\n11     1    11    27   643  3044\n12     1    12    28   921  2925\n13     1    13    36  1196  2867\n\ncor.test(mofo1$inc, mofo1$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -6.8451, df = 11, p-value = 2.782e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9699609 -0.6921361\nsample estimates:\n       cor \n-0.8999278 \n\n\n\n#Experimento 2\n\nmofo1 <- mofo |> \n  filter (study ==2)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     2     1    76  1331  2257\n 2     2     2    44   756  2393\n 3     2     3    24   338  2401\n 4     2     4    33   581  2568\n 5     2     5    37   588  2320\n 6     2     6    34   231  2308\n 7     2     7    31   925  2389\n 8     2     8    16   119  2614\n 9     2     9    10   394  2681\n10     2    10     8   206  2694\n11     2    11    15   275  2674\n12     2    12     7   131  2666\n13     2    13    19   588  2454\n\ncor.test(mofo1$inc, mofo1$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -4.6638, df = 11, p-value = 0.0006894\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9426562 -0.4790750\nsample estimates:\n       cor \n-0.8149448 \n\n\n\n#Experimento 3\n\nmofo1 <- mofo |> \n  filter (study ==3)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n\ncor.test(mofo1$inc, mofo1$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 3.105e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n\n\n\n#Experimento 4\n\nmofo1 <- mofo |> \n  filter (study ==4)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     4     1    69  6216  1893\n 2     4     2    39  2888  2451\n 3     4     3    41  2272  2232\n 4     4     4    39  2868  2609\n 5     4     5    40  2412  2383\n 6     4     6    40  2372  2480\n 7     4     7    44  3424  2577\n 8     4     8    43  1744  2367\n 9     4     9    26  1456  2769\n10     4    10    29  1732  2907\n11     4    11    30  1080  2298\n12     4    12    34  1592  2976\n13     4    13    44  3268  2200\n\ncor.test(mofo1$inc, mofo1$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -3.7242, df = 11, p-value = 0.003357\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9194503 -0.3327077\nsample estimates:\n       cor \n-0.7467931 \n\n\n\ncor.test(mofo1$inc, mofo1$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -3.7242, df = 11, p-value = 0.003357\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9194503 -0.3327077\nsample estimates:\n       cor \n-0.7467931 \n\npcor <- cor(mofo1 |> select(3:5))\nlibrary(corrplot)\ncorrplot (pcor, method = 'number', type = \"lower\")\n\n\n\n\n\ncor.test(mofo$inc, mofo$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo$inc and mofo$yld\nt = -2.9274, df = 50, p-value = 0.005133\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5934601 -0.1223842\nsample estimates:\n       cor \n-0.3825092 \n\npcor <- cor(mofo |> select(3:5))\nlibrary(corrplot)\ncorrplot (pcor, method = 'number', type = \"lower\")\n\n\n\n\n\nshapiro.test(mofo1$yld)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mofo1$yld\nW = 0.97728, p-value = 0.9636\n\ncor.test(mofo1$inc, mofo1$yld, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  mofo1$inc and mofo1$yld\nS = 611.02, p-value = 0.01077\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.6786265 \n\npcor <- cor(mofo |> select(3:5))\nlibrary(corrplot)\ncorrplot (pcor, method = 'number', type = \"lower\")"
  },
  {
    "objectID": "Aula 15.html",
    "href": "Aula 15.html",
    "title": "Comparação de Frequência",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\nsurvey <- read_excel(\"dados-diversos.xlsx\",\"survey\")\n\nlibrary(janitor)\n\nsurvey |> \n  tabyl (year, species) |> \n  adorn_percentages()\n\n year      Fgra      Fspp\n 2009 0.8490566 0.1509434\n 2010 0.8657407 0.1342593\n 2011 0.7567568 0.2432432"
  },
  {
    "objectID": "Aula 15.html#gráfico-de-barras---frequência",
    "href": "Aula 15.html#gráfico-de-barras---frequência",
    "title": "Comparação de Frequência",
    "section": "Gráfico de barras - frequência",
    "text": "Gráfico de barras - frequência\n\nsurvey |> \n  filter(residue != \"NA\") |> \n  count (residue, species) |> \n  ggplot(aes(residue, n, fill = species))+\n  geom_col()"
  },
  {
    "objectID": "Aula 15.html#frequência-de-classe",
    "href": "Aula 15.html#frequência-de-classe",
    "title": "Comparação de Frequência",
    "section": "Frequência de classe",
    "text": "Frequência de classe\n\nchisq.test\nRealiza testes de tabela de contingência qui-quadrado e testes de qualidade de ajuste.\n\nq <- table (survey$residue, survey$species)\nchisq.test(q)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 1.1997, df = 1, p-value = 0.2734"
  },
  {
    "objectID": "Aula 15.html#para-frequências-mais-baixas",
    "href": "Aula 15.html#para-frequências-mais-baixas",
    "title": "Comparação de Frequência",
    "section": "Para frequências mais baixas",
    "text": "Para frequências mais baixas\n\nfisher.test\nExecuta o teste exato de Fisher para testar o nulo de independência de linhas e colunas em uma tabela de contingência com marginais fixos.\n\nfisher.test(q)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  q\np-value = 0.2118\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.357205 1.311411\nsample estimates:\nodds ratio \n 0.6819103 \n\nq <- table (survey$residue, survey$inc_class)\nchisq.test(q)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 2.6165, df = 1, p-value = 0.1058\n\nsurvey |> \n  filter(residue != \"NA\") |> \n  count (residue, inc_class) |> \n  ggplot(aes(residue, n, fill = inc_class))+\n  geom_col()\n\n\n\n#Dados de levantamento - variável categórica nominal"
  },
  {
    "objectID": "Aula 15.html#cruzamento-entre-variáveis",
    "href": "Aula 15.html#cruzamento-entre-variáveis",
    "title": "Comparação de Frequência",
    "section": "Cruzamento entre variáveis",
    "text": "Cruzamento entre variáveis\n\nsurvey |> count (year)\n\n# A tibble: 3 × 2\n   year     n\n  <dbl> <int>\n1  2009   265\n2  2010   216\n3  2011   185\n\n#Frequência de ocorrência por ano\n\ntable (survey$year, survey$species)\n\n      \n       Fgra Fspp\n  2009  225   40\n  2010  187   29\n  2011  140   45\n\n\n\ncurve <- read_excel(\"dados-diversos.xlsx\",\"curve\")\n\ncurve2 <- curve |> \n  group_by(Irrigation, day) |> \n  summarise(mean_severity = mean (severity),\n            sd_severity = sd(severity))\n\ncurve2 |> ggplot(aes(day,mean_severity, color=Irrigation))+\n  geom_point()+\n  geom_line()\n\n\n\ncurve2 |> ggplot(aes(day,mean_severity, color=Irrigation))+\n  geom_point()+\n  geom_errorbar(aes(ymin=mean_severity - sd_severity,\n                    ymax = mean_severity + sd_severity),\n                width = 0.1)+\n  geom_line()\n\n\n\nlibrary(epifitter)\n\ncurve3 <- curve |> \n  group_by(Irrigation, rep) |> \n  summarise(audpc = AUDPC(day, severity,\n                          y_proportion = F)) |> \n  pivot_wider(1, names_from = Irrigation,\n            values_from = audpc)\n\nt.test(curve3$Drip, curve$Furrow)\n\n\n    One Sample t-test\n\ndata:  curve3$Drip\nt = 51.206, df = 2, p-value = 0.0003812\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 12.26473 14.51493\nsample estimates:\nmean of x \n 13.38983 \n\n\n\nlibrary(gsheet)\n\ntw <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1t5xftb0xSRPNFhM7h_MiPNtwt2UFUcm9/edit#gid=1594889893\")\ntw |> \n  group_by(cult,silicio,hai) |> \n  summarise (mean_lesion = mean (as.numeric(lesion_size)),\n             sd_lesion = sd(lesion_size)) |> \n  ggplot(aes(hai,mean_lesion, color = silicio))+\n  geom_line()+\n  geom_point()+\n  geom_errorbar(aes(ymin=mean_lesion - sd_lesion,\n                    ymax = mean_lesion + sd_lesion),\n                width = 0.1)+\n  facet_wrap(~cult)+\n   labs (y = \"Lesion size (mm)\", x = \"Hours after inoculation\")+\n  ggthemes::theme_few()+\n  scale_color_grey()\n\n\n\nlibrary(agricolae)\n\ntw2 <- tw |>\n  group_by(exp,cult,silicio,rep) |> \n  summarise(audpc=audpc(lesion_size, hai)) |> \n  filter (audpc > 0)\n\ntw2 |> \n  ggplot(aes(cult,audpc, color = silicio))+\n  geom_boxplot()+\n  facet_wrap(~ exp)\n\n\n\n\n\naov1 <- aov(sqrt(audpc) ~exp*cult*silicio, data = tw2)\nsummary(aov1)\n\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nexp               1    0.1     0.1   0.033  0.85737    \ncult              1  135.0   135.0  74.615 2.67e-10 ***\nsilicio           1  839.4   839.4 464.034  < 2e-16 ***\nexp:cult          1    0.0     0.0   0.000  0.99843    \nexp:silicio       1    0.0     0.0   0.002  0.96060    \ncult:silicio      1   19.3    19.3  10.671  0.00239 ** \nexp:cult:silicio  1    0.0     0.0   0.015  0.90324    \nResiduals        36   65.1     1.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.893).\n\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.316).\n\nlibrary(emmeans)\nm1 <- emmeans (aov1, ~cult | silicio, type = \"response\")"
  },
  {
    "objectID": "Aula 16.html",
    "href": "Aula 16.html",
    "title": "Construindo Mapas no R",
    "section": "",
    "text": "#remotes::install_github(\"ropensci/rnaturalearthhires\")\n\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(r4pde)\nlibrary(tidyr)\n\nsbr <- RustSoybean\nsbr2 <- sbr|> separate (planting, into = c(\"year\",\"month\", \"day\"), sep= \"-\",\n           remove= FALSE)\n\n\nBRA <- ne_countries(country= \"Brazil\",\n                    returnclass= \"sf\")\n\nlibrary(tidyverse)\n\nggplot(BRA)+\n  geom_sf(color= \"white\",\n          fill = \"darkgreen\")+\n  theme_classic()\n\n\n\n\n\nBRA <- ne_states(country= \"Brazil\",\n                    returnclass= \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\nlibrary(tidyverse)\nlibrary(ggsn)\n\nggplot(BRA)+\n  geom_sf(color= \"black\",\n          fill = \"white\")+\n  geom_sf(data= MG, color = \"black\", fill= \"darkblue\")+\n  geom_point(data=sbr, aes(longitude,latitude), alpha = 0.5)\n\n\n\n  theme_void()\n\nList of 97\n $ line                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ rect                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ text                      :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                     : NULL\n $ aspect.ratio              : NULL\n $ axis.title                : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.title.x              : NULL\n $ axis.title.x.top          : NULL\n $ axis.title.x.bottom       : NULL\n $ axis.title.y              : NULL\n $ axis.title.y.left         : NULL\n $ axis.title.y.right        : NULL\n $ axis.text                 : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.text.x               : NULL\n $ axis.text.x.top           : NULL\n $ axis.text.x.bottom        : NULL\n $ axis.text.y               : NULL\n $ axis.text.y.left          : NULL\n $ axis.text.y.right         : NULL\n $ axis.ticks                : NULL\n $ axis.ticks.x              : NULL\n $ axis.ticks.x.top          : NULL\n $ axis.ticks.x.bottom       : NULL\n $ axis.ticks.y              : NULL\n $ axis.ticks.y.left         : NULL\n $ axis.ticks.y.right        : NULL\n $ axis.ticks.length         : 'simpleUnit' num 0points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x       : NULL\n $ axis.ticks.length.x.top   : NULL\n $ axis.ticks.length.x.bottom: NULL\n $ axis.ticks.length.y       : NULL\n $ axis.ticks.length.y.left  : NULL\n $ axis.ticks.length.y.right : NULL\n $ axis.line                 : NULL\n $ axis.line.x               : NULL\n $ axis.line.x.top           : NULL\n $ axis.line.x.bottom        : NULL\n $ axis.line.y               : NULL\n $ axis.line.y.left          : NULL\n $ axis.line.y.right         : NULL\n $ legend.background         : NULL\n $ legend.margin             : NULL\n $ legend.spacing            : NULL\n $ legend.spacing.x          : NULL\n $ legend.spacing.y          : NULL\n $ legend.key                : NULL\n $ legend.key.size           : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height         : NULL\n $ legend.key.width          : NULL\n $ legend.text               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.align         : NULL\n $ legend.title              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.align        : NULL\n $ legend.position           : chr \"right\"\n $ legend.direction          : NULL\n $ legend.justification      : NULL\n $ legend.box                : NULL\n $ legend.box.just           : NULL\n $ legend.box.margin         : NULL\n $ legend.box.background     : NULL\n $ legend.box.spacing        : NULL\n $ panel.background          : NULL\n $ panel.border              : NULL\n $ panel.spacing             : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ panel.spacing.x           : NULL\n $ panel.spacing.y           : NULL\n $ panel.grid                : NULL\n $ panel.grid.major          : NULL\n $ panel.grid.minor          : NULL\n $ panel.grid.major.x        : NULL\n $ panel.grid.major.y        : NULL\n $ panel.grid.minor.x        : NULL\n $ panel.grid.minor.y        : NULL\n $ panel.ontop               : logi FALSE\n $ plot.background           : NULL\n $ plot.title                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 1.2\n  ..$ hjust        : num 0\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 5.5points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ plot.title.position       : chr \"panel\"\n $ plot.subtitle             :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 5.5points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ plot.caption              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : num 1\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 5.5points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ plot.caption.position     : chr \"panel\"\n $ plot.tag                  :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 1.2\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ plot.tag.position         : chr \"topleft\"\n $ plot.margin               : 'simpleUnit' num [1:4] 0lines 0lines 0lines 0lines\n  ..- attr(*, \"unit\")= int 3\n $ strip.background          : NULL\n $ strip.background.x        : NULL\n $ strip.background.y        : NULL\n $ strip.clip                : chr \"inherit\"\n $ strip.placement           : NULL\n $ strip.text                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ strip.text.x              : NULL\n $ strip.text.x.bottom       : NULL\n $ strip.text.x.top          : NULL\n $ strip.text.y              : NULL\n $ strip.text.y.left         : NULL\n $ strip.text.y.right        : NULL\n $ strip.switch.pad.grid     : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ strip.switch.pad.wrap     : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\nggplot(BRA)+\n  #annotation_north_arrow (location = \"bl\",\n                          #style = north_arrow_nautical())+\n  #annotation_scale(location=\"br\")+\n  geom_sf(color= \"black\",\n          fill = \"white\")+\n  geom_point(data=sbr2, aes(longitude,latitude, color= year, \n                            size = severity), alpha = 0.5)+\n  geom_hline(yintercept = -23, linetype= \"dashed\", color = \"black\")+\n  theme_minimal()+\n    labs(color = \"Planting Year\")+\n    theme(legend.position = \"right\")\n\n\n\n  facet_wrap(~year)\n\n<ggproto object: Class FacetWrap, Facet, gg>\n    compute_layout: function\n    draw_back: function\n    draw_front: function\n    draw_labels: function\n    draw_panels: function\n    finish_data: function\n    init_scales: function\n    map_data: function\n    params: list\n    setup_data: function\n    setup_params: function\n    shrink: TRUE\n    train_scales: function\n    vars: function\n    super:  <ggproto object: Class FacetWrap, Facet, gg>\n\n\n\nlibrary(sf)\nshapefile <- st_read(\"malha/BR_Municipios_2022.shp\")\n\nReading layer `BR_Municipios_2022' from data source \n  `C:\\Users\\dyeni\\Documents\\GitHub\\FIP606\\website\\malha\\BR_Municipios_2022.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5572 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -73.99045 ymin: -33.75118 xmax: -28.84764 ymax: 5.271841\nGeodetic CRS:  SIRGAS 2000\n\nggplot(BRA)+\n  geom_sf(data = shapefile)\n\n\n\n\n\nggplot(BRA)+\n  geom_sf(data = shapefile, color = \"black\", fill = \"darkgreen\")+\n  geom_sf(data= MG, color = \"black\", fill= \"darkblue\")"
  },
  {
    "objectID": "Aula 17.html",
    "href": "Aula 17.html",
    "title": "Regressão não linear e EC50",
    "section": "",
    "text": "A regressão não linear é um método de localizar um modelo não linear do relacionamento entre a variável dependente e um conjunto de variáveis independentes. Diferentemente da regressão linear tradicional, que é restrita à estimativa de modelos lineares, a regressão não linear pode estimar modelos com relacionamentos arbitrários entre variáveis independentes e dependentes. Isso é feito usando algoritmos de estimação iterativos.\n\nlibrary(gsheet)\nlibrary(tidyverse)\n\ndat <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/15pCj0zljvd-TGECe67OMt6sa21xO8BqUgv4d-kU8qi8/edit#gid=0\")\n\noptions(scipen = 999)\n\ndat2<- dat |>\n  select(-Isolate, -Population) |> \n  group_by(Code, Year, Dose) |> \n  summarise(GC_mean=mean(GC))\n\nFGT152 <- dat2 |> \n  filter(Code ==\"FGT152\")\n\nFGT152 |> \n  ggplot(aes(Dose, GC_mean))+\n  geom_point()+\n  geom_line()\n\n\n\ndat2 |> ggplot(aes(Dose, GC_mean))+\n  geom_point()+\n  geom_line()+\n  facet_wrap(~Code)"
  },
  {
    "objectID": "Aula 17.html#ec50-com-pacote-drc",
    "href": "Aula 17.html#ec50-com-pacote-drc",
    "title": "Regressão não linear e EC50",
    "section": "EC50 com pacote DRC",
    "text": "EC50 com pacote DRC\nO controle efetivo para 50% de inibição do crescimento (EC 50) é uma estatística padrão para avaliar as relações dose-resposta. Muitos pacotes de software estatístico estão disponíveis para estimar as relações dose-resposta, mas, recentemente, um pacote de código aberto (“drc”) em R foi utilizado. Este pacote é altamente adaptável, tendo muitos modelos para descrever as relações dose-resposta e flexibilidade para descrever as relações horméticas e EC 50 absoluto e relativo .\nLeia mais em < https://apsjournals.apsnet.org/doi/full/10.1094/PDIS-06-17-0873-SR >\n\nlibrary(drc)\n\ndrc1 <- drm(GC_mean ~ Dose, data = FGT152,\n    fct = LL.3())\nplot(drc1)\n\n\n\nsummary(drc1)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  0.401905   0.053427  7.5225  0.001672 ** \nd:(Intercept) 47.540342   1.459890 32.5643 5.302e-06 ***\ne:(Intercept)  7.220130   2.340119  3.0854  0.036739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.993805 (4 degrees of freedom)\n\nED (drc1, 50)\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   7.2201     2.3401\n\n\n\nOutro exemplo de modelo\n\ndrc2 <- drm(GC_mean ~ Dose, data = FGT152,\n    fct = W1.3())\nplot(drc2)\n\n\n\nsummary(drc2)\n\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value   p-value    \nb:(Intercept)  0.28354    0.04760  5.9567  0.003987 ** \nd:(Intercept) 48.38112    2.09996 23.0390 2.103e-05 ***\ne:(Intercept) 30.12379   12.58003  2.3946  0.074796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.680509 (4 degrees of freedom)\n\nED (drc2, 50)\n\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   8.2704     3.6719\n\n\n\nAIC (drc1, drc2)\n\n     df      AIC\ndrc1  4 33.60846\ndrc2  4 37.75192\n\n\n\nlibrary(ec50estimator)\n\ndf_ec50 <- estimate_EC50 (GC_mean ~ Dose,\n                          data = dat2,\n                          isolate_col = \"Code\",\n                          interval = \"delta\",\n                          fct = drc::LL.3())\n\ndf_ec50 |> \n  ggplot(aes(Estimate, reorder (ID, Estimate)))+\n  geom_point()+\n  geom_errorbar(aes(xmin=Lower,\n                    xmax=Upper, width = 0.1))+\n  xlim(0,30)"
  },
  {
    "objectID": "Aula 18.html",
    "href": "Aula 18.html",
    "title": "Teste de Tukey e Scott Knott (Pacote ExpDes.pt)",
    "section": "",
    "text": "Pacote para análise de delineamentos experimentais (DIC, DBC e DQL), experimentos em esquema fatorial duplo (em DIC e DBC), experimentos em parcelas subdivididas (em DIC e DBC), experimentos em esquema fatorial duplo com um tratamento adicional (em DIC e DBC), experimentos em fatorial triplo (em DIC e DBC) e experimentos em esquema fatorial triplo com um tratamento adicional (em DIC e DBC), fazendo análise de variância e comparação de múltiplas médias (para tratamentos qualitativos), ou ajustando modelos de regressao até a terceira potência (para tratamentos quantitativos); analise de residuos.\n\nwarning(FALSE)\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ExpDes.pt)"
  },
  {
    "objectID": "Aula 18.html#teste-de-tukey-com-pacote-expdes.pt-experimento-em-dic",
    "href": "Aula 18.html#teste-de-tukey-com-pacote-expdes.pt-experimento-em-dic",
    "title": "Teste de Tukey e Scott Knott (Pacote ExpDes.pt)",
    "section": "Teste de Tukey com pacote ExpDes.pt (Experimento em DIC)",
    "text": "Teste de Tukey com pacote ExpDes.pt (Experimento em DIC)\nComando para execução do teste:\ndic (trat, resp, quali = TRUE, mcomp = “tukey”, nl = FALSE, hvar = “bartlett”, sigT = 0.05, sigF = 0.05, unfold = NULL)\n\nInsectSprays\n\n   count spray\n1     10     A\n2      7     A\n3     20     A\n4     14     A\n5     14     A\n6     12     A\n7     10     A\n8     23     A\n9     17     A\n10    20     A\n11    14     A\n12    13     A\n13    11     B\n14    17     B\n15    21     B\n16    11     B\n17    16     B\n18    14     B\n19    17     B\n20    17     B\n21    19     B\n22    21     B\n23     7     B\n24    13     B\n25     0     C\n26     1     C\n27     7     C\n28     2     C\n29     3     C\n30     1     C\n31     2     C\n32     1     C\n33     3     C\n34     0     C\n35     1     C\n36     4     C\n37     3     D\n38     5     D\n39    12     D\n40     6     D\n41     4     D\n42     3     D\n43     5     D\n44     5     D\n45     5     D\n46     5     D\n47     2     D\n48     4     D\n49     3     E\n50     5     E\n51     3     E\n52     5     E\n53     3     E\n54     6     E\n55     1     E\n56     1     E\n57     3     E\n58     2     E\n59     6     E\n60     4     E\n61    11     F\n62     9     F\n63    15     F\n64    22     F\n65    15     F\n66    16     F\n67    13     F\n68    10     F\n69    26     F\n70    26     F\n71    24     F\n72    13     F\n\ninsects <- InsectSprays\n\ndic(insects$spray,\n    insects$count,\n    mcomp = \"tukey\")\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM     Fc      Pr>Fc\nTratamento  5 2668.8 533.77 34.702 3.1826e-17\nResiduo    66 1015.2  15.38                  \nTotal      71 3684.0                         \n------------------------------------------------------------------------\nCV = 41.28 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.02225989 \nATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais!\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  9.085122e-05 \nATENCAO: a 5% de significancia, as variancias nao podem ser consideradas homogeneas!\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    F   16.66667 \na    B   15.33333 \na    A   14.5 \n b   D   4.916667 \n b   E   3.5 \n b   C   2.083333 \n------------------------------------------------------------------------"
  },
  {
    "objectID": "Aula 18.html#teste-de-tukey-com-pacote-expdes.pt-dados-transformados-em-raiz---sqrt",
    "href": "Aula 18.html#teste-de-tukey-com-pacote-expdes.pt-dados-transformados-em-raiz---sqrt",
    "title": "Teste de Tukey e Scott Knott (Pacote ExpDes.pt)",
    "section": "Teste de Tukey com pacote ExpDes.pt (dados transformados em raiz - sqrt)",
    "text": "Teste de Tukey com pacote ExpDes.pt (dados transformados em raiz - sqrt)\n\ninsects$count2 <- sqrt(insects$count)\n\ndic(insects$spray,\n    insects$count2,\n    mcomp = \"tukey\")\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ      QM     Fc      Pr>Fc\nTratamento  5  88.438 17.6876 44.799 6.3345e-20\nResiduo    66  26.058  0.3948                  \nTotal      71 114.496                          \n------------------------------------------------------------------------\nCV = 22.34 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6813773 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.5855673 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    F   4.018617 \na    B   3.876631 \na    A   3.760678 \n b   D   2.164354 \n bc      E   1.809461 \n  c      C   1.244857 \n------------------------------------------------------------------------"
  },
  {
    "objectID": "Aula 18.html#teste-de-scott-knott-expdes.pt",
    "href": "Aula 18.html#teste-de-scott-knott-expdes.pt",
    "title": "Teste de Tukey e Scott Knott (Pacote ExpDes.pt)",
    "section": "Teste de Scott Knott ExpDes.pt",
    "text": "Teste de Scott Knott ExpDes.pt\nO método de Scott-Knott é eficiente nas aplicações em experimentos em que queremos comparar diferentes tratamentos. Seu intuito é separar as médias dos tratamentos em grupos homogêneos, assim minimizando soma de quadrados dentro; e maximizando-a entre os grupos, sem sobrepô-los. Para isso, é necessário ordenar as médias para que suas respectivas classificações sejam possíveis, determinar o número de partições possíveis, com a finalidade de realizar essa maximização entre grupos.\n\nExperimento em DIC\n\n#Agrupamento pelo teste de Scott Knott: O teste agrupa médias e serve para 1 fator apenas.\n\ndic(insects$spray,\n    insects$count2,\n    mcomp = \"sk\")\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ      QM     Fc      Pr>Fc\nTratamento  5  88.438 17.6876 44.799 6.3345e-20\nResiduo    66  26.058  0.3948                  \nTotal      71 114.496                          \n------------------------------------------------------------------------\nCV = 22.34 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6813773 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.5855673 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Scott-Knott\n------------------------------------------------------------------------\n  Grupos Tratamentos   Medias\n1      a           F 4.018617\n2      a           B 3.876631\n3      a           A 3.760678\n4      b           D 2.164354\n5      b           E 1.809461\n6      c           C 1.244857\n------------------------------------------------------------------------\n\n# Verificar os dados iguais sem ambiguidade\n# O teste de SK precisa atender as premissas (Normalidade e Homocedasticidade)\n\n\n\nExperimento em DBC\nNesse caso preciso incluir a coluna do bloco.\n\n#Exemplo:\n\ndata(ex5)\nattach(ex5)\nfat2.dbc(trat, genero, bloco, sabor, quali=c(TRUE,TRUE),\nmcomp=\"lsd\", fac.names=c(\"Amostras\",\"Genero\"), sigT = 0.05,\nsigF = 0.05, unfold=NULL)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  Amostras \nFATOR 2:  Genero \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                 GL     SQ QM      Fc   Pr>Fc\nBloco            19  97.82  4 1.55116 0.07832\nAmostras          3  19.37  5 1.94522 0.12537\nGenero            1   7.66  6 2.30677 0.13118\nAmostras*Genero   3   3.92  2 0.39356 0.75783\nResiduo         133 441.43  3                \nTotal           159 570.19  1                \n------------------------------------------------------------------------\nCV = 27.58 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.005428379 \nATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais!\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nAmostras\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1    10g  6.850\n2    15g  6.975\n3    15t  6.075\n4    20t  6.525\n------------------------------------------------------------------------\nGenero\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      F 6.8250\n2      M 6.3875\n------------------------------------------------------------------------"
  },
  {
    "objectID": "Aula 2.html",
    "href": "Aula 2.html",
    "title": "FIP 606",
    "section": "",
    "text": "---\n    title: \"Comandos básicos para começar no R\"\n    format: html\n    ---"
  },
  {
    "objectID": "Aula 2.html#download-r-studio",
    "href": "Aula 2.html#download-r-studio",
    "title": "FIP 606",
    "section": "Download R Studio",
    "text": "Download R Studio\nLink para instalação do R e do R Studio (https://posit.co/download/rstudio-desktop/)"
  },
  {
    "objectID": "Aula 2.html#instalação-de-pacotes",
    "href": "Aula 2.html#instalação-de-pacotes",
    "title": "FIP 606",
    "section": "Instalação de Pacotes",
    "text": "Instalação de Pacotes\nA instalação de pacotes pode ser feita através do menu: Tools > Install packages…, ou ainda:\n\n#install.packages(nome do pacote de interesse)"
  },
  {
    "objectID": "Aula 2.html#carregamento-de-pacotes",
    "href": "Aula 2.html#carregamento-de-pacotes",
    "title": "FIP 606",
    "section": "Carregamento de pacotes",
    "text": "Carregamento de pacotes\nApós a instalação, o carregamento de pacotes pode ser feito na opção “packages”, onde na barra de busca é inserido o nome do programa de interesse e logo em seguida ele é selecionado ou ainda através de um comando, o “library”. É importante lembrar que antes de iniciar qualquer trabalho no R, os pacotes de interesse precisam ser carregados.\n\nlibrary(tidyverse)\nlibrary(remotes)\nlibrary(r4pde)"
  },
  {
    "objectID": "Aula 2.html#remoção-de-mensagens-de-alerta-no-carregamento-de-pacotes",
    "href": "Aula 2.html#remoção-de-mensagens-de-alerta-no-carregamento-de-pacotes",
    "title": "FIP 606",
    "section": "Remoção de mensagens de alerta no carregamento de pacotes",
    "text": "Remoção de mensagens de alerta no carregamento de pacotes\nA remoção das mensagens de alerta que são emitidas por alguns pacotes deixa a visualização das informações dispostas mais limpa.\n\nwarning(FALSE)"
  },
  {
    "objectID": "Aula 2.html#invocando-a-função-de-um-pacote",
    "href": "Aula 2.html#invocando-a-função-de-um-pacote",
    "title": "FIP 606",
    "section": "Invocando a função de um pacote",
    "text": "Invocando a função de um pacote\nApós o carregamento do pacote de interesse, é possível trazer as informações de planilhas externas para dentro do R. Abaixo, um exemplo:\nSe os dados que serão trabalhados estão dispostos em uma planilha do Google Sheet, então faz-se necessário instalar um pacote que consiga trabalhar esse tipo de planilha. Então como primeiro passo, instalo e carrego esse pacote.\n\n## Carregamento de planilhas do Google Sheet\n\nlibrary(gsheet)\n\nApós o carregamento do pacote, um nome é dado para o meu conjunto e uma função é atribuída. (A atribuição de funções é dada pelo “<-”). Nesse caso, o conjunto foi nomeado “d” e a função atribuída foi “gsheet2tbl”, que pertence ao pacote “gsheet”. Entre parenteses, o link da planilha disponível no Google Sheet.\n\nd <- gsheet2tbl (\"docs.google.com/spreadsheets/d/1I9mJsS5QnXF2TNNntTy-HrcdHmIF9wJ8ONYvEJTXSNo\")\n\ndplyr::arrange(d, mpg)\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  10.4     8  472    205  2.93  5.25  18.0     0     0     3     4\n 2  10.4     8  460    215  3     5.42  17.8     0     0     3     4\n 3  13.3     8  350    245  3.73  3.84  15.4     0     0     3     4\n 4  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 5  14.7     8  440    230  3.23  5.34  17.4     0     0     3     4\n 6  15       8  301    335  3.54  3.57  14.6     0     1     5     8\n 7  15.2     8  276.   180  3.07  3.78  18       0     0     3     3\n 8  15.2     8  304    150  3.15  3.44  17.3     0     0     3     2\n 9  15.5     8  318    150  2.76  3.52  16.9     0     0     3     2\n10  15.8     8  351    264  4.22  3.17  14.5     0     1     5     4\n# ℹ 22 more rows\n\n#O dplyr, função do pacote Tidyverse, anteriormente carregado, seguido de \":: arrange\" alterou a ordem as linhas da minha tabela. Deixou os dados em ordem crescente, melhorando a visualização."
  },
  {
    "objectID": "Aula 2.html#instalação-de-pacotes-do-github",
    "href": "Aula 2.html#instalação-de-pacotes-do-github",
    "title": "FIP 606",
    "section": "Instalação de Pacotes do GitHub",
    "text": "Instalação de Pacotes do GitHub\nO R usa como base para instalação de pacotes o CRAN, mas é possível que durante o desenvolvimento do trabalho, o pacote de uma base externa seja necessário, como por exemplo o GitHub. Para conseguir trazer para dentro do R o pacote de interesse, adota-se os seguintes passos:\n\nlibrary (remotes)\n\n#install_github(\"nome do usuário do GitHub/nome do pacote de interesse\")\n\ninstall_github(\"emdelponte/r4pde\")"
  },
  {
    "objectID": "Aula 2.html#usando-o-pacote-r4pde",
    "href": "Aula 2.html#usando-o-pacote-r4pde",
    "title": "FIP 606",
    "section": "Usando o pacote r4pde",
    "text": "Usando o pacote r4pde\nUma vez instalado, o pacote da base externa vai funcionar com as funções disponíveis no R e trabalhar com os dados de interesse. Como, por exemplo:\n\n# Variável \"unit\": Um vetor numérico que representa a unidade de medida.\n\nunit <- c(1:12)\n\n# Variável \"class\": Um vetor de fator que representa os rótulos da classe.\n\nclass <- c(2,3,1,1,3,4,5,0,2,5,2,1)\n\n# Criando um conjunto de dados chamado \"ratings\" onde eu junto as variáveis \"unit\" e \"class\". A junção das variáveis se deu pela função atribuída \"data.frame\".\n\nratings <- data.frame(unit, class)\n\n#DSI: Calcula o Índice de Gravidade da Doença.\n\nDSI(unit = ratings$unit, class = ratings$class, max = 6)\n\n[1] 40.27778\n\n#max: Escala numérica que representa o valor máximo possível da unidade de medida.\n\n#$: Variável dentro do data frame.\n\nratings$class\n\n [1] 2 3 1 1 3 4 5 0 2 5 2 1\n\nmean (ratings$class) #média\n\n[1] 2.416667\n\nsd (ratings$class) #desvio padrão\n\n[1] 1.621354\n\n# Sumarização dos dados\nsummary (ratings)\n\n      unit           class      \n Min.   : 1.00   Min.   :0.000  \n 1st Qu.: 3.75   1st Qu.:1.000  \n Median : 6.50   Median :2.000  \n Mean   : 6.50   Mean   :2.417  \n 3rd Qu.: 9.25   3rd Qu.:3.250  \n Max.   :12.00   Max.   :5.000"
  },
  {
    "objectID": "Aula 3.html",
    "href": "Aula 3.html",
    "title": "Importação de dados",
    "section": "",
    "text": "Os dados que serão trabalhados no R podem vir de diversos bancos de dados, abaixo serão mostradas as formas de importar as informações de alguns desses bancos."
  },
  {
    "objectID": "Aula 3.html#de-pacotes-do-r",
    "href": "Aula 3.html#de-pacotes-do-r",
    "title": "Importação de dados",
    "section": "De pacotes do R",
    "text": "De pacotes do R\nO próprio R possui uma base de dados e é possível importar e trabalhar com essas informações. Abaixo o conjunto de dados chamado “cars”.\n\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ncars2 <- cars\nspeed <- cars2$speed\nspeed\n\n [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n[26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25\n\n#Atribuindo \"cars\" a \"cars2\" um data frame é criado, e é a partir dele que o trabalho começa.\n\nOu então a importação de dados pode vir de algum pacote, como é o caso do conjunto “RustSoybean”, que pertence ao pacote “r4pde”.\n\n# Não esquecer de carregar o pacote onde os dados de interesse estão.\n\nlibrary (r4pde)\ndf <- RustSoybean\ndf\n\n# A tibble: 34 × 7\n   epidemia latitude longitude local              planting   detection  severity\n      <dbl>    <dbl>     <dbl> <chr>              <date>     <date>        <dbl>\n 1       23    -23.0     -50.1 Cambara            2003-11-25 2004-02-02     24  \n 2       24    -24.0     -52.4 Campo Mourao       2003-11-28 2004-02-02     21  \n 3       31    -15.5     -55.2 Campo Verde        2004-11-20 2005-01-25     78  \n 4        3    -13.3     -44.6 Correntina         2002-11-10 2003-01-03     85  \n 5       15    -13.3     -44.6 Correntina         2003-11-28 2004-01-31     25  \n 6       34    -25.4     -51.5 Guarapuava         2004-11-29 2005-03-14     32  \n 7        7    -29.2     -53.7 Julio Castilhos    2002-12-15 2003-04-10     40  \n 8       13    -12.1     -45.8 Luis Eduardo Maga… 2003-11-12 2004-02-15     39.2\n 9       33    -12.1     -45.8 Luis Eduardo Maga… 2004-11-19 2005-01-25     55  \n10        1    -23.3     -51.2 Londrina           2002-11-06 2003-02-03     45  \n# ℹ 24 more rows"
  },
  {
    "objectID": "Aula 3.html#de-planilhas-do-excel",
    "href": "Aula 3.html#de-planilhas-do-excel",
    "title": "Importação de dados",
    "section": "De planilhas do Excel",
    "text": "De planilhas do Excel\nÉ comum também que os dados estejam dispostos em planilhas do Excel. Para importar os dados desse tipo de arquivo, existe um pacote específico no R.\n\nlibrary (readxl)\n\n#Nesse primeiro caso, todos os dados, de todas as abas da planilha serão carregado no R.\nmagnesio <- read_excel (\"dados-diversos.xlsx\")\n\n#Já no segundo caso, ao inserir o nome da planilha de interesse e na sua frente o número ou nome da aba específica que será trabalhada, apenas o dados daquela aba serão importados.\nescala <- read_excel (\"dados-diversos.xlsx\", 2)\nescala2 <- read_excel (\"dados-diversos.xlsx\", \"escala\")"
  },
  {
    "objectID": "Aula 3.html#de-arquivos-csv",
    "href": "Aula 3.html#de-arquivos-csv",
    "title": "Importação de dados",
    "section": "De arquivos CSV",
    "text": "De arquivos CSV\nAinda é possível importar dados que são trabalhados no software do Excel, mas que apresentam um formato diferente do padrão “xlsx”.\n\nlibrary (tidyverse)\n\nmagnesio2 <- read.csv (\"dados-diversos.csv\")\nmagnesio3 <- read_csv (\"dados-diversos.csv\")\nmagnesio3\n\n# A tibble: 60 × 4\n   Irrigation   rep   day severity\n   <chr>      <dbl> <dbl>    <dbl>\n 1 Furrow         1     0     0.01\n 2 Furrow         2     0     0.01\n 3 Furrow         3     0     0.01\n 4 Furrow         1     7     0.04\n 5 Furrow         2     7     0.04\n 6 Furrow         3     7     0.04\n 7 Furrow         1    14     0.1 \n 8 Furrow         2    14     0.1 \n 9 Furrow         3    14     0.11\n10 Furrow         1    21     0.11\n# ℹ 50 more rows"
  },
  {
    "objectID": "Aula 3.html#de-arquivos-txt",
    "href": "Aula 3.html#de-arquivos-txt",
    "title": "Importação de dados",
    "section": "De arquivos txt",
    "text": "De arquivos txt\nDocumentos de texto padrão.\n\nmagnesio4 <- read.table (\"dados-diversos.txt\", header = TRUE)"
  },
  {
    "objectID": "Aula 3.html#do-google-sheet",
    "href": "Aula 3.html#do-google-sheet",
    "title": "Importação de dados",
    "section": "Do Google Sheet",
    "text": "Do Google Sheet\nPlanilhas on-line disponíveis no Google Sheet.\n\nlibrary (gsheet)\n\nmagnesio5 <- gsheet2tbl (\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit?usp=sharing\")\n\nsurvey <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=366054269\")\n \nfusarium <- read.csv (\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/fusarium_banana.csv\")\n\nfusarium\n\n          lon       lat  marker field\n1   -50.83339 -20.46100 plantas    11\n2   -50.83339 -20.46100 plantas    11\n3   -50.83333 -20.46121 plantas    11\n4   -50.83332 -20.46124 plantas    11\n5   -50.83332 -20.46127 plantas    11\n6   -50.83331 -20.46136 plantas    11\n7   -50.83318 -20.46127 plantas    11\n8   -50.83319 -20.46124 plantas    11\n9   -50.83319 -20.46122 plantas    11\n10  -50.83325 -20.46114 plantas    11\n11  -50.83317 -20.46130 plantas    11\n12  -50.83315 -20.46144 plantas    11\n13  -50.83317 -20.46152 plantas    11\n14  -50.83320 -20.46155 plantas    11\n15  -50.83319 -20.46157 plantas    11\n16  -50.83318 -20.46156 plantas    11\n17  -50.83320 -20.46163 plantas    11\n18  -50.83319 -20.46182 plantas    11\n19  -50.83319 -20.46184 plantas    11\n20  -50.83319 -20.46188 plantas    11\n21  -50.83319 -20.46194 plantas    11\n22  -50.83309 -20.46210 plantas    11\n23  -50.83309 -20.46204 plantas    11\n24  -50.83307 -20.46185 plantas    11\n25  -50.83308 -20.46182 plantas    11\n26  -50.83307 -20.46180 plantas    11\n27  -50.83306 -20.46156 plantas    11\n28  -50.83304 -20.46141 plantas    11\n29  -50.83297 -20.46147 plantas    11\n30  -50.83301 -20.46149 plantas    11\n31  -50.83299 -20.46150 plantas    11\n32  -50.83303 -20.46171 plantas    11\n33  -50.83300 -20.46191 plantas    11\n34  -50.83302 -20.46195 plantas    11\n35  -50.83304 -20.46198 plantas    11\n36  -50.83302 -20.46203 plantas    11\n37  -50.83303 -20.46203 plantas    11\n38  -50.83303 -20.46214 plantas    11\n39  -50.83296 -20.46226 plantas    11\n40  -50.83292 -20.46189 plantas    11\n41  -50.83284 -20.46129 plantas    11\n42  -50.83281 -20.46128 plantas    11\n43  -50.83284 -20.46121 plantas    11\n44  -50.83286 -20.46117 plantas    11\n45  -50.83287 -20.46111 plantas    11\n46  -50.83293 -20.46106 plantas    11\n47  -50.83275 -20.46122 plantas    11\n48  -50.83277 -20.46130 plantas    11\n49  -50.83280 -20.46151 plantas    11\n50  -50.83280 -20.46155 plantas    11\n51  -50.83286 -20.46223 plantas    11\n52  -50.83287 -20.46236 plantas    11\n53  -50.83275 -20.46230 plantas    11\n54  -50.83264 -20.46160 plantas    11\n55  -50.83261 -20.46140 plantas    11\n56  -50.83260 -20.46137 plantas    11\n57  -50.83266 -20.46107 plantas    11\n58  -50.83263 -20.46151 plantas    11\n59  -50.83264 -20.46169 plantas    11\n60  -50.83265 -20.46172 plantas    11\n61  -50.83264 -20.46210 plantas    11\n62  -50.83264 -20.46216 plantas    11\n63  -50.83264 -20.46218 plantas    11\n64  -50.83265 -20.46219 plantas    11\n65  -50.83261 -20.46231 plantas    11\n66  -50.83249 -20.46230 plantas    11\n67  -50.83249 -20.46182 plantas    11\n68  -50.83250 -20.46176 plantas    11\n69  -50.83252 -20.46175 plantas    11\n70  -50.83252 -20.46174 plantas    11\n71  -50.83253 -20.46175 plantas    11\n72  -50.83254 -20.46163 plantas    11\n73  -50.83255 -20.46163 plantas    11\n74  -50.83255 -20.46159 plantas    11\n75  -50.83254 -20.46148 plantas    11\n76  -50.83252 -20.46122 plantas    11\n77  -50.83250 -20.46102 plantas    11\n78  -50.83348 -20.46101 plantas    11\n79  -50.83345 -20.46124 plantas    11\n80  -50.83346 -20.46126 plantas    11\n81  -50.83345 -20.46126 plantas    11\n82  -50.83338 -20.46136 plantas    11\n83  -50.83339 -20.46143 plantas    11\n84  -50.83348 -20.46106 plantas    11\n85  -50.83357 -20.46141 plantas    11\n86  -50.83337 -20.46184 plantas    11\n87  -50.83320 -20.46214 plantas    11\n88  -50.83337 -20.46191 plantas    11\n89  -50.83344 -20.46180 plantas    11\n90  -50.83348 -20.46174 plantas    11\n91  -50.83355 -20.46154 plantas    11\n92  -50.83362 -20.46138 plantas    11\n93  -50.83365 -20.46136 plantas    11\n94  -50.83369 -20.46105 plantas    11\n95  -50.83372 -20.46097 plantas    11\n96  -50.83379 -20.46103 plantas    11\n97  -50.83379 -20.46114 plantas    11\n98  -50.83378 -20.46121 plantas    11\n99  -50.83379 -20.46123 plantas    11\n100 -50.83380 -20.46125 plantas    11\n101 -50.83380 -20.46124 plantas    11\n102 -50.83359 -20.46180 plantas    11\n103 -50.83357 -20.46185 plantas    11\n104 -50.83354 -20.46189 plantas    11\n105 -50.83353 -20.46193 plantas    11\n106 -50.83351 -20.46194 plantas    11\n107 -50.83331 -20.46229 plantas    11\n108 -50.83340 -20.46213 plantas    11\n109 -50.83350 -20.46195 plantas    11\n110 -50.83351 -20.46192 plantas    11\n111 -50.83354 -20.46189 plantas    11\n112 -50.83356 -20.46186 plantas    11\n113 -50.83360 -20.46178 plantas    11\n114 -50.83360 -20.46176 plantas    11\n115 -50.83363 -20.46172 plantas    11\n116 -50.83380 -20.46139 plantas    11\n117 -50.83382 -20.46118 plantas    11\n118 -50.83379 -20.46101 plantas    11\n119 -50.83396 -20.46131 plantas    11\n120 -50.83359 -20.46211 plantas    11\n121 -50.83357 -20.46214 plantas    11\n122 -50.83362 -20.46209 plantas    11\n123 -50.83366 -20.46208 plantas    11\n124 -50.83367 -20.46207 plantas    11\n125 -50.83367 -20.46206 plantas    11\n126 -50.83369 -20.46205 plantas    11\n127 -50.83369 -20.46205 plantas    11\n128 -50.83378 -20.46187 plantas    11\n129 -50.83388 -20.46170 plantas    11\n130 -50.83403 -20.46104 plantas    11\n131 -50.83404 -20.46100 plantas    11\n132 -50.83412 -20.46099 plantas    11\n133 -50.83413 -20.46102 plantas    11\n134 -50.83409 -20.46148 plantas    11\n135 -50.83406 -20.46151 plantas    11\n136 -50.83385 -20.46184 plantas    11\n137 -50.83384 -20.46184 plantas    11\n138 -50.83378 -20.46202 plantas    11\n139 -50.83376 -20.46203 plantas    11\n140 -50.83376 -20.46207 plantas    11\n141 -50.83368 -20.46223 plantas    11\n142 -50.83377 -20.46218 plantas    11\n143 -50.83386 -20.46194 plantas    11\n144 -50.83387 -20.46191 plantas    11\n145 -50.83424 -20.46098 plantas    11\n146 -50.83438 -20.46112 plantas    11\n147 -50.83406 -20.46191 plantas    11\n148 -50.83399 -20.46206 plantas    11\n149 -50.83390 -20.46237 plantas    11\n150 -50.83396 -20.46228 plantas    11\n151 -50.83407 -20.46203 plantas    11\n152 -50.83322 -20.46119 plantas    11\n153 -50.83322 -20.46122 plantas    11\n154 -50.83318 -20.46131 plantas    11\n155 -50.83318 -20.46133 plantas    11\n156 -50.83329 -20.46133 plantas    11\n157 -50.83330 -20.46122 plantas    11\n158 -50.83331 -20.46118 plantas    11\n159 -50.83332 -20.46114 plantas    11\n160 -50.83246 -20.46236 polygon    11\n161 -50.83247 -20.46092 polygon    11\n162 -50.83447 -20.46096 polygon    11\n163 -50.83391 -20.46241 polygon    11\n\nlibrary (googlesheets4)"
  },
  {
    "objectID": "Aula 4.html",
    "href": "Aula 4.html",
    "title": "Gráficos em ggplot",
    "section": "",
    "text": "No ggplot, os gráficos são construídos camada por camada. A primeira camada é dada pela função “ggplot()”, onde é determinada a estética da distribuição dos dados que serão trabalhados. A segunda camada é dada pela função “geom_()” que vai definir o tipo de gráfico gerado.\n\nwarning(FALSE)\n\nlibrary (tidyverse)\n\nmg <- read_csv(\"dados-diversos.csv\")\n\n#Depois de carregar o pacote de interesse e trazer os dados que serão trabalhados para dentro do R, começamos a construção do gráfico. É importante lembrar que o pacote \"ggplot2\", responsável pela construção dos gráfico, está dentro do pacote \"tidyverse\".\n\nmg |> ggplot (aes(Irrigation, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)\n\n\n\n#A função escolhida para gerar a segunda camada do gráfico foi \"geom_point()\", gerando um gráfico de pontos ou dispersão.\n\nÉ possível ainda criar um subconjunto de um data frame, usando a função “filter()”.\n\nmg |> \n  filter (rep == 1) |> \n  ggplot (aes(day,severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\n  geom_line()+\n  facet_wrap(~rep)\n\n\n\n#É interessante que existe a possibilidade trabalhar diferentes modelos de gráficos para melhor explorar os dados, como nesse caso onde foi usado \"geom_point()\" e \"geom_line()\".\n\n#Uma outra observação interessante é a função \"facet\". Essa é uma funcionalidade útil do \"ggplot2\", pois permite usar facets para replicar um gráfico para cada categoria de uma variável.\n\n\nmg |> \n  filter (rep == 2) |> \n  ggplot (aes(day,severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\n  geom_line()\n\n\n\n\n\nmg |> \n  filter (rep == 3) |> \n  ggplot (aes(day,severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\n  geom_line()\n\n\n\n\nCom a função “select()” é possível selecionar as colunas de interesse.\n\nmg |> \n  select (Irrigation, severity) |> \n  ggplot (aes(Irrigation, severity, shape = Irrigation))+\n  geom_point(alpha = 0.5)+\n  geom_line()\n\n\n\n\n\nmg |> \n  select (Irrigation, severity) |> \n  ggplot (aes(Irrigation, severity, shape = Irrigation))+\n  geom_boxplot()\n\n\n\n\n\nmg |> \n  select (Irrigation, severity) |> \n  ggplot (aes(Irrigation, severity, shape = Irrigation))+\n  geom_boxplot()+\n  geom_point(alpha = 0.5)\n\n\n\n\n\nmg |> \n  select (day, rep, severity) |> \n  ggplot (aes(day, severity))+\n  geom_boxplot()\n\n\n\n\n\nmg |> select (day, rep, severity) |> \n  ggplot (aes(day, severity))+\n  geom_boxplot()+\n  geom_point(alpha = 0.5)\n\n\n\n\n\nmg |> \n  select (day, rep, severity) |> \n  ggplot (aes(day, severity, group = day))+\n  geom_boxplot()\n\n\n\n\n\nmg |> \n  select (day, rep, severity) |> \n  ggplot(aes(day, severity, group = day))+\n  geom_point()\n\n\n\n\n\nmg |> \n  select (day, rep, severity) |> \n  ggplot (aes(day, severity))+\n  geom_point()\n\n\n\n\nCom a função “group_by()” a variável existente é convertida é um agrupado onde as operações são executadas por um grupo. Já a função “summarize()” resume um conjunto de dados utilizando alguma métrica de interesse.\n\nmg |> \n  select (day, rep, severity) |> \n  group_by (day) |> \n  summarize(sev = mean (severity)) |> \n  ggplot (aes(day, sev))+\n  geom_point()\n\n\n\n\n\nmg2 <- mg |> \n  select (day, rep, severity) |> \n  group_by (day) |> \n  summarize(sev = mean (severity))\n\n\nmg2 |> \n  ggplot (aes(day, sev))+\n  geom_point()\n\n\n\n\n\nmg2 |> \n  ggplot (aes(day, sev))+\n  geom_point()+\n  geom_line()\n\n\n\n\nCom o gráfico pronto é possível adicionar a ele título, subtítulo, legenda, fonte e qualquer outra informação que for interessante ser apresentadada. Essas informações também são consideradas camadas e são criadss ou modificados pela função “labs()”.\n\nmg2 |> \n  ggplot (aes(day, sev))+\n  geom_point()+\n  geom_line()+\n  labs (x = \"Time (days)\", y = \"Severity (Proportion)\")\n\n\n\n\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_point()+\n  geom_line()+\n  labs (x = \"Time (days)\", y = \"Severity (%)\")\n\n\n\n#\"*100\" para respostas em porcentagem.\n\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_point()+\n  geom_line()+\n  ylim (0,100)+\n  labs (x = \"Time (days)\", y = \"Severity (%)\", \n        title = \"My first ggplot\", \n        subtitle = \"D. Rodrigues\", \n        caption = \"Source: FIP 606\")\n\n\n\n\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_point()+\n  geom_line()+\n  labs (x = \"Time (days)\", y = \"Severity (%)\")\n\n\n\n\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_point()+\n  geom_line()+\n  ylim (0,100)+\n  labs (x = \"Time (days)\", y = \"Severity (%)\", \n        title = \"My first ggplot\", subtitle = \"D. Rodrigues\", \n        caption = \"Source: FIP 606\")+\n  theme_minimal()\n\n\n\n#\"theme_()\" permite escolher um tema para o gráfico, que vai variar de acordo com a escolha de cada um.\n\nDentro da função “geom_()” é possível personalizar a apresentação das formas que foram definidas para o gráfico, adicionando cores, linhas mais expressivas, pontos maiores, etc.\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_point(size = 3, color = \"orange\")+\n  geom_line(color = \"orange\")+\n  ylim (0,100)+\n  labs (x = \"Time (days)\", y = \"Severity (%)\", \n        title = \"My first ggplot\", subtitle = \"D. Rodrigues\", \n        caption = \"Source: FIP 606\")+\n  theme_minimal()\n\n\n\n#\"ylim()\" permite escolher os valores de variação do eixo y.\n\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_point(size = 3, color = \"orange\")+\n  geom_line(color = \"orange\")+\n  ylim (0,100)+\n  scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42, 49, 56, 63))+\n  labs (x = \"Time (days)\", y = \"Severity (%)\", \n        title = \"My first ggplot\", subtitle = \"D. Rodrigues\", \n        caption = \"Source: FIP 606\")+\n  theme_minimal()\n\n\n\n#\"scale_x_continuous()\" permite escolher os valores de variação do eixo x.\n\n#Para salvar seu gráfico em forma de imagem, use a função \"ggsave()\", escolha um nome e na frente \".png\". É possível também definir a cor de fundo da imagem que o gráfico será salvo, bem como suas dimensões.\n\nggsave(\"myfirstggplot.png\", bg = \"white\", width = 4, height = 3)\n\n\nmg2 |> \n  ggplot (aes(day, sev*100))+\n  geom_line(color = \"orange\")+\n  geom_point(size = 3, color = \"orange\")+\n  scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42, 49, 56, 63))+\n  scale_x_continuous(n.breaks = 5, limits = c(0,100))+\n  labs (x = \"Time (days)\", y = \"Severity (%)\", \n        title = \"My first ggplot\", subtitle = \"D. Rodrigues\", \n        caption = \"Source: FIP 606\")+\n  theme_minimal()\n\n\n\nggsave(\"myfirstggplot.png\", bg = \"white\", width = 4, height = 3)"
  },
  {
    "objectID": "Aula 5.html",
    "href": "Aula 5.html",
    "title": "Gráficos em ggplot - parte 2",
    "section": "",
    "text": "Continuando a aula antetior sobre a construção de gráficos em ggplot, nessa aula veremos alguns outros modelos de gráficos disponíveis no pacote “ggplot2()”."
  },
  {
    "objectID": "Aula 5.html#visualização-de-dados-em-gráficos",
    "href": "Aula 5.html#visualização-de-dados-em-gráficos",
    "title": "Gráficos em ggplot - parte 2",
    "section": "Visualização de dados em gráficos",
    "text": "Visualização de dados em gráficos\n\nmg |> ggplot (aes(trat,comp))+\n  geom_boxplot(outlier.color = NA,\n               fill = \"yellow\",\n               size = 0.5,\n               width = 0.2) +\n  geom_jitter(width = 0.15,\n              height = 0,\n              size = 2,\n              color = \"black\") +\n  scale_y_continuous(limits = c(7,19), n.breaks = 6) +\n  labs (y = \"Lesion Size (mm)\", x = \"\") +\n  theme_minimal()\n\n\n\n#Nesse caso a função \"ggsave()\" está, além de salvando a imagem em \".png\", criando uma pasta chamada \"figuras\", onde as imagens serão salvas.\n\nggsave (\"figuras/plot2.png\", bg = \"white\")\n\n\nmg |> \n  group_by (trat) |> \n  summarise(comp_mean = mean (comp), comp_sd = sd (comp)) |> \n  ggplot (aes(trat, comp_mean)) +\n  geom_col (fill = \"purple\",\n            width = 0.3,\n            color = \"black\") +\n   scale_y_continuous(limits = c(0,20), n.breaks = 6) +\n  geom_errorbar(aes(ymin = comp_mean , \n                    ymax = comp_mean + comp_sd,\n                    width = 0))\n\n\n\n\n\np_box = mg |> \n  group_by (trat) |> \n  summarise(comp_mean = mean (comp), comp_sd = sd (comp)) |> \n  ggplot (aes(trat, comp_mean)) +\n  geom_col (fill = \"purple\",\n            width = 0.3,\n            color = \"black\") +\n  geom_point ()+\n   scale_y_continuous(limits = c(0,20), n.breaks = 6) +\n  geom_errorbar(aes(ymin = comp_mean - comp_sd , \n                    ymax = comp_mean + comp_sd,\n                    width = 0.05)) +\n  labs (y = \"Lesion Size (mm)\", x = \"\")\n\np_box\n\n\n\n\n\nmg |> \n  group_by (trat) |> \n  summarise(comp_mean = mean (comp),\n            comp_sd = sd (comp)) |> \n  ggplot (aes(trat, comp_mean)) +\n  geom_point ()+\n   scale_y_continuous(limits = c(0,20), n.breaks = 6) +\n  geom_errorbar(aes(ymin = comp_mean - comp_sd , \n                    ymax = comp_mean + comp_sd,\n                    width = 0.05)) +\n  theme_minimal() +\n  labs (y = \"Lesion Size (mm)\", x = \"\")\n\n\n\nggsave (\"figuras/plot2.2.png\", bg = \"white\", \n        width = 4, \n        height = 4)\n\n\np_means = mg |> \n  group_by (trat) |> \n  summarise(comp_mean = mean (comp),\n            comp_sd = sd (comp)) |> \n  ggplot (aes(trat, comp_mean)) +\n  geom_point ()+\n   scale_y_continuous(limits = c(0,20), n.breaks = 6) +\n  geom_errorbar(aes(ymin = comp_mean - comp_sd , \n                    ymax = comp_mean + comp_sd,\n                    width = 0.05)) +\n  theme_minimal() +\n  labs (y = \"Lesion Size (mm)\", x = \"\")\n\np_means"
  },
  {
    "objectID": "Aula 5.html#comparação-de-dois-gráficos",
    "href": "Aula 5.html#comparação-de-dois-gráficos",
    "title": "Gráficos em ggplot - parte 2",
    "section": "Comparação de dois gráficos",
    "text": "Comparação de dois gráficos\nCom o pacote “patchwork” é possível combinar ggplots separados em um mesmo gráfico.\n\nlibrary (patchwork)\n\np_box | p_means\n\n\n\n\n\nlibrary (patchwork)\n\np_box / p_means\n\n\n\n\n\nlibrary (patchwork)\n\n(p_box | p_means) +\n  plot_annotation(tag_levels = \"A\",\n                  title = \"Graphics that impress\")\n\n\n\n#O \"plot_annotation()\" adiciona ao seu \"patchwork\" informações úteis como títulos, legendas, fonte, etc.\n\nggsave (\"figuras/combined.png\")\n\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", sheet = \"survey\")\n\nsurvey |> \n  filter (state == \"RS\") |> \n  count (species) |> \n  ggplot(aes(species, n)) +\n  geom_col(width = 0.3,\n           fill = \"darkblue\",\n           color = \"black\") +\n  coord_flip () +\n  labs (x = \"\", y = \"Number of isolates\", \n        title = \"Graphics that impress\",\n        subtitle = \"I made it\") +\n  theme_classic()\n\n\n\n#A função \"coord_flip()\" cria gráficos horizontais.\n\nggsave (\"figuras/barplot.png\", bg = \"white\")\n\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", sheet = \"survey\")\n\nsurvey |> \n  filter (state == \"RS\") |> \n  count (species, residue) |> \n  ggplot(aes(species, n)) +\n  geom_col(width = 0.3,\n           fill = \"darkblue\",\n           color = \"black\") +\n  coord_flip () +\n  facet_wrap(~residue, ncol = 1) +\n  labs (x = \"\", y = \"Number of isolates\", \n        title = \"Graphics that impress\",\n        subtitle = \"I made it\") +\n  theme_bw()\n\n\n\nggsave (\"figuras/barplot2.png\", bg = \"white\")"
  },
  {
    "objectID": "Aula 6.html",
    "href": "Aula 6.html",
    "title": "Gráficos de dispersão e Histogramas",
    "section": "",
    "text": "library (tidyverse)\nlibrary (readxl)\n\nfungicida <- read_excel(\"dados-diversos.xlsx\", 6)"
  },
  {
    "objectID": "Aula 6.html#gráficos-de-dispersão",
    "href": "Aula 6.html#gráficos-de-dispersão",
    "title": "Gráficos de dispersão e Histogramas",
    "section": "Gráficos de dispersão",
    "text": "Gráficos de dispersão\nO gráfico de dispersão é uma ferramenta bastante usada em estatística para visualizar a relação entre duas variáveis quantitativas. Ao plotar os pontos no gráfico, é possível detectar padrões e tendências nos dados, além de identificar possíveis correlações entre as variáveis.\n\nfungicida |> \n  ggplot(aes(trat, sev))+\n  geom_jitter(width = 0.1,\n              color = \"gray20\")+\n  stat_summary(fun = mean,\n               color = \"blue\")\n\n\n\n\n\nfungicida |> \n  ggplot(aes(trat, sev))+\n  geom_jitter(width = 0.1,\n              color = \"gray20\")+\n  stat_summary(fun.data = mean_se,\n               color = \"blue\")\n\n\n\n\n\nfungicida |> \n  ggplot(aes(sev, yld, \n             color = trat,\n             size = yld))+\n  geom_point()\n\n\n\n\n\nfungicida |> ggplot(aes(sev, yld, \n                        color = trat))+\n  geom_point(size = 3)\n\n\n\n\n\nfungicida |> ggplot(aes(sev, yld))+\n  geom_point(size = 2)+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nfungicida |> ggplot(aes(sev, yld))+\n  geom_point(size = 2,\n             color = \"gray20\")+\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"blue\",\n              linetype = 2,\n              size = 1)\n\n\n\n\n\nmilho <- read_excel (\"dados-diversos.xlsx\", 10)\n\nmilho |> ggplot (aes(method, index, color = method))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~ hybrid)\n\n\n\n\n\nmilho <- read_excel (\"dados-diversos.xlsx\", 10)\n\nmilho |> ggplot (aes(hybrid, yield, color = method))+\n  geom_jitter(width = 0.1)"
  },
  {
    "objectID": "Aula 6.html#histogramas",
    "href": "Aula 6.html#histogramas",
    "title": "Gráficos de dispersão e Histogramas",
    "section": "Histogramas",
    "text": "Histogramas\nO histograma consiste numa representação gráfica de dados que são divididos em classes. Assim, esta representação gráfica é feita com o objetivo de conferir como um processo se comporta em relação a suas especificidades.\n\ny = milho |> ggplot(aes(x= yield)) + \n  geom_histogram(bins = 10,\n                 fill = \"lightblue\",\n                 color = \"black\")\n\n\ni = milho |> ggplot(aes(x= index)) + \n  geom_histogram(bins = 10,\n                 fill = \"lightblue\",\n                 color = \"black\")\n\n\nlibrary(patchwork)\n\n(y | i) +\nplot_annotation(tag_levels = \"A\",\n                title = \"Corn = yield and index\",\n                subtitle = \"D. Rodrigues\")\n\n\n\nggsave (\"figuras/milho.png\", bg = \"white\",\n         width = 6, \n        height = 4)\n\n\nmilho |> ggplot(aes(x=yield))+\n  geom_density()\n\n\n\n\n\ninsect <- read_excel(\"dados-diversos.xlsx\", \"mortalidade\")\n\ninsect |> \n  pivot_longer(2:3, names_to = \"status\",\n               values_to = \"value\") |> \n  ggplot (aes(inseticida, value,\n              fill = status)) + geom_col()"
  },
  {
    "objectID": "Aula 8.html",
    "href": "Aula 8.html",
    "title": "Teste t",
    "section": "",
    "text": "Trabalhando um conjunto de dados e aplicando o “Teste t”. Hipótese para o conjunto de dados: Magnésio é benéfico para a planta. Reduz o tamanho da lesão."
  },
  {
    "objectID": "Aula 8.html#teste-t",
    "href": "Aula 8.html#teste-t",
    "title": "Teste t",
    "section": "Teste T",
    "text": "Teste T\nO teste t compara duas médias e mostra se as diferenças entre essas médias são significativas. A necessidade de determinar se duas médias de amostras são diferentes entre si é uma situação extremamente frequente em pesquisas científicas.Como todo teste estatístico, o teste t também tem como produto a medida do p valor. Ou seja, calculamos a probabilidade da diferença encontrada (entre as médias) terem sido por acaso.\n\nt <- t.test(mg2$Mg2, mg2$Ctrl)\n\n# Se p valor for menor que 5% ( p < 0.05), a tradição científica é de rejeitarmos a hipótese de que as diferenças sejam por acaso (rejeitamos a hipótese nula) e alegamos termos encontrado uma diferença estatísticamente significativa.\n\nlibrary(report)\nreport(t)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and mg2$Ctrl\n(mean of x = 10.52, mean of y = 15.68) suggests that the effect is negative,\nstatistically significant, and large (difference = -5.16, 95% CI [-6.49,\n-3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12, -2.14])\n\n#Pacote \"report\" -> Este pacote converte modelos estatísticos e quadros de dados em relatórios textuais adequados para publicação, garantindo padronização e qualidade na apresentação de resultados.\n\n\nmagnesio |> ggplot(aes(trat, comp))+\n  stat_summary(fun.data = \"mean_se\")+\n  annotate(geom = \"text\", x = 0.7,\n           y = 19, label = \"t = 8.15; P < 0.001\")\n\n\n\n#Os números de x e y são as coordenadas de onde ficaram meus dados."
  },
  {
    "objectID": "Aula 9.html",
    "href": "Aula 9.html",
    "title": "Testes paramétricos e não paramétricos",
    "section": "",
    "text": "Nesta seção trataremos de formas de analisar dados em experimentos onde as causas da variação na resposta são controladas o máximo possível e o erro experimental minimizado. Veremos os tipos de análise de acordo com o número e tipo de variáveis independentes (níveis do fator) e também o número de tratamentos ou grupos a serem comparados. Iniciaremos primeiramente com os casos mais simples quanto ao número de grupos e iremos avançando conforme aumentamos a complexidade do experimento bem com algumas variações possíveis quanto ao número e tipo de variáveis resposta de interesse.\n\n\nUm pesquisador conduziu um experimento com o objetivo de avaliar o efeito de um micronutriente, o magnésio (Mg), adicionado na solução do solo cultivado com plantas de arroz, no manejo de uma doença fúngica. O experimento foi conduzido em delineamento inteiramente casualizado com 10 repetições, sendo cada repetição um vaso de planta. Um dos tratamentos é o chamado controle, ou testemunha, sem o suplemento mineral. O segundo é aquele com o suplemento do Mg na dose de 2 mM. Em cada uma das repetições foi obtido um valor médio do comprimento de lesões em um determinado tempo após a inoculação.\n\n\n\n\nlibrary(magrittr) # para usar pipes\nlibrary(ggplot2) # para gráficos\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(tidyr)\n\n\ndata_mg <- read_excel(\"dados-diversos.xlsx\")\nhead(data_mg)\n\n# A tibble: 6 × 3\n  trat    rep  comp\n  <chr> <dbl> <dbl>\n1 Mg2       1   9  \n2 Mg2       2  12.5\n3 Mg2       3  10  \n4 Mg2       4   8  \n5 Mg2       5  13.2\n6 Mg2       6  11  \n\n\nA maneira mais simples é visualizar, no caso de mais de 6 repetições, usando boxplots juntamente com os dados de cada repetição.\n\ndata_mg |> \n  ggplot(aes(trat, comp)) +\n  geom_boxplot(outlier.color = NA) +\n  geom_jitter(width = 0.1, shape = 1)\n\n\n\n\nVamos obter estatísticas que descrevem o conjunto, seja a tendência central ou a dispersão dos dados. No caso, será a média, variância, desvio padrão, erro padrão e intervalo de confiança - esse último para inferência visual.\n\ndat2 <- data_mg |> \n  group_by(trat) |> \n  summarise(mean_comp = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n - 1),\n    ci = se_comp * qt(0.025, df = 9) # paramétrico\n  )\ndat2\n\n# A tibble: 2 × 7\n  trat  mean_comp sd_comp var_comp     n se_comp     ci\n  <chr>     <dbl>   <dbl>    <dbl> <int>   <dbl>  <dbl>\n1 Ctrl       15.7    1.27     1.61    10   0.424 -0.958\n2 Mg2        10.5    1.54     2.39    10   0.515 -1.16 \n\n\nJá podemos visualizar os dados com as estatísticas calculadas. Abaixo, as barras verticais represntam o intervalo de confiança 95%.\n\ndat2 %>%\n  ggplot(aes(trat, mean_comp)) +\n  geom_jitter(\n    data = data_mg, aes(trat, comp),\n    color = \"grey\",\n    width = 0.05\n  ) +\n  geom_errorbar(aes(\n    ymin = mean_comp - ci,\n    ymax = mean_comp + ci\n  ),\n  width = 0.05\n  ) +\n  geom_point(size = 3)\n\n\n\n\nO conjunto está no formato largo, assim a variável resposta de interesse está apenas em uma coluna. Existem várias formas de separar em dois vetores os dados de resposta para cada tratamento. Uma delas é por meio da função spread do pacote tidyr, a qual coloca as respostas em duas colunas, uma para cada tratamento. Vamos criar o conjunto data_mg2.\n\ndata_mg2 <- data_mg %>%\n  spread(trat, comp)\ndata_mg2\n\n# A tibble: 10 × 3\n     rep  Ctrl   Mg2\n   <dbl> <dbl> <dbl>\n 1     1  13.7   9  \n 2     2  15.9  12.5\n 3     3  15.7  10  \n 4     4  14.2   8  \n 5     5  15.9  13.2\n 6     6  16.5  11  \n 7     7  18    10.8\n 8     8  14.4   9.5\n 9     9  16.4  10.8\n10    10  16    10.4"
  },
  {
    "objectID": "Aula 9.html#análise-inferencial",
    "href": "Aula 9.html#análise-inferencial",
    "title": "Testes paramétricos e não paramétricos",
    "section": "Análise inferencial",
    "text": "Análise inferencial\nUsando o conjunto original, vamos visualizar as respostas (tamanho da lesão) para cada tratamento, já que O ggplot2 requer os dados no formato largo.\n\n# usando pipes\ndata_mg %>%\n  ggplot(aes(trat, comp)) +\n  geom_jitter(width = 0.1, height = 0) +\n  ylim(5, 20) # ajusta o eixo y para melhor visualização\n\n\n\n\n\nHomocedasticidade\nNo caso de dois grupos, a função que pode ser usada é a var.test do R. Vamos usar o formato largo e chamar os dois vetores do conjunto. Verifique o P-valor na saída da análise.\n\nattach(data_mg2) # vamos facilitar o uso dos vetores\nvar.test(Mg2, Ctrl)\n\n\n    F test to compare two variances\n\ndata:  Mg2 and Ctrl\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n\n\n\n\nNormalidade\nA normalidade pode ser testada por meio de procedimentos visuais e testes específicos.\n\nshapiro.test(Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n\nshapiro.test(Ctrl)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Ctrl\nW = 0.93886, p-value = 0.5404\n\n\nAnálise visual da premissa de normalidade.\n\nqqnorm(Mg2)\nqqline(Mg2)\n\n\n\nqqnorm(Ctrl)\nqqline(Ctrl)\n\n\n\n\n\nmagnesio3 <- data_mg %>%\n  group_by(trat) %>%\n  summarize(\n    mu = mean(comp),\n    sd = sd(comp),\n    n = length(comp),\n    se = sd / sqrt(n),\n    ciu = mu + (qt(0.025, df = n - 1) * se),\n    cil = mu - (qt(0.025, df = n - 1) * se)\n  )\n\n\n\nIntervalo de confiança\n\nmagnesio3 %>%\n  ggplot(aes(trat, mu, color = trat)) +\n  geom_point(size = 3) +\n  ylim(7,20)+\n  geom_errorbar(aes(min = cil, max = ciu), width = 0.05, size = 1) +\n  labs(x = \"Tratamento\", y = \"Valor\", title = \"Magnesium effect on lesion expansion\")\n\n\n\n\n\n\nTeste de hipótese\n\nt.test(Mg2, Ctrl, paired = F)\n\n\n    Welch Two Sample t-test\n\ndata:  Mg2 and Ctrl\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\n\n\nAlternativas\nSe as premissas de normalidade não fossem atendidas, qual o teste que poderia ser usado? Nesse caso de dois grupos há duas possibilidades, uma é usar um teste não paramétrico ou um teste baseado em reamostragem (bootstrapping) dos dados, os quais independem do modelo de distribuição.\nUsando os mesmos dados podemos notar que o resultado é idêntico porém com P-valores diferentes."
  },
  {
    "objectID": "Aula 9.html#preparo-pré-análise-1",
    "href": "Aula 9.html#preparo-pré-análise-1",
    "title": "Testes paramétricos e não paramétricos",
    "section": "Preparo pré-análise",
    "text": "Preparo pré-análise\n\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  <chr>      <chr>    <dbl>    <dbl>      <dbl>            <dbl>          <dbl>\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.560    0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.695    0.751      0.925            0.802        0.336  \n\n\n\nescala %>%\n  gather(component, statistics, 3:7) %>% # formato longo\n  ggplot(aes(reorder(assessment, statistics), statistics)) +\n  geom_jitter(width = 0.05) +\n  facet_wrap(~component, scales = \"free_y\")\n\n\n\n\nPrepara os dados para análise. Cria os vetores de cada grupo para cada variável. Vamos fazer abaixo para acurácia.\n\n# arruma os dados\nescala2 <- select(escala, assessment, rater, acuracia)\nescala3 <- spread(escala2, assessment, acuracia)\n\n\nPremissas\n\n## homocedasticidade dois grupos\nattach(escala3)\nvar.test(Aided1, Unaided)\n\n\n    F test to compare two variances\n\ndata:  Aided1 and Unaided\nF = 0.17041, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04232677 0.68605885\nsample estimates:\nratio of variances \n         0.1704073 \n\n## normalidade\nshapiro.test(Aided1)$p.value\n\n[1] 0.4260888\n\nshapiro.test(Unaided)$p.value\n\n[1] 0.1131276\n\nqqnorm(Aided1)\nqqline(Aided1)\n\n\n\nqqnorm(Unaided)\nqqline(Unaided)\n\n\n\n\n\n\nAnálise inferencial\n\nescala4 <- summarize(group_by(escala2, assessment),\n  mu = mean(acuracia),\n  sd = sd(acuracia),\n  n = length(acuracia),\n  se = sd / sqrt(n),\n  ciu = mu + (qt(0.025, df = n - 1) * se),\n  cil = mu - (qt(0.025, df = n - 1) * se)\n)\n\nVisualiza média e intervalo de confiança\n\nggplot(escala4, aes(assessment, mu)) +\n  geom_point(stat = \"identity\", size = 4) +\n  geom_errorbar(aes(min = cil, max = ciu),\n    width = .05\n  )\n\n\n\n\nVisualiza cada avaliador\n\nggplot(escala2, aes(reorder(assessment, acuracia), acuracia, group = rater)) + geom_point(stat = \"identity\", size = 3, shape = 1) +\n  geom_line(size = 1, color = \"gray70\") + facet_wrap(~rater, nrow = 5)\n\n\n\n\n\n\nTeste t paramétrico\nNote que as amostras são pareadas - mesmo avaliador em dois tempos, portanto há dependência.\n\n## teste t para amostras pareadas\nt_escala <- t.test(escala3$Aided1, escala3$Unaided,\n  paired = TRUE,\n  var.equal = F\n)\n\nt_escala\n\n\n    Paired t-test\n\ndata:  escala3$Aided1 and escala3$Unaided\nt = 5.9364, df = 9, p-value = 0.000219\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1144707 0.2554241\nsample estimates:\nmean difference \n      0.1849474"
  },
  {
    "objectID": "Aula 9.html#teste-não-paramétrico",
    "href": "Aula 9.html#teste-não-paramétrico",
    "title": "Testes paramétricos e não paramétricos",
    "section": "Teste não paramétrico",
    "text": "Teste não paramétrico\n\nwilcox. test\nO teste T de Wilcoxon substitui o t de Student para amostras pareadas quando os dados não satisfazem as exigências deste último. Foi também desenvolvido por F. Wilcoxon em 1945 e baseia-se nos postos das diferenças intrapares. O teste de Wilcoxon (Wilcoxon Matched-Pairs; Wilcoxon signed-ranks test) é um método não-paramétrico para comparação de duas amostras pareadas. A princípio são calculados os valores numéricos da diferença entre cada par, sendo possível três condições: aumento (+), diminuição (-) ou igualdade (=). Uma vez calculadas todas as diferenças entre os valores obtidos para cada par de dados, essas diferenças são ordenadas pelo seu valor absoluto (sem considerar o sinal), substituindo-se então os valores originais pelo posto que ocupam na escala ordenada. O teste da hipótese de igualdade entre os grupos é baseado na soma dos postos das diferenças negativas e positivas.\n\nwilcox.test(escala3$Aided1, escala3$Unaided, paired = TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  escala3$Aided1 and escala3$Unaided\nV = 55, p-value = 0.001953\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olá, seja bem-vindo!",
    "section": "",
    "text": "Que bom que chegou. Eu me chamo Dyênici, é um prazer te ter aqui!!\n\n\n\n\n\n\n\n\n\nSobre mim\nEngenheira Agrônoma pelo Instituto Federal de Educação, Ciência e Tecnologia do Espírito Santo - Campus Santa Teresa. Atuei como estagiária voluntária no Laboratório de Diagnose de Doenças de Plantas do Campus e fui bolsista de iniciação científica do Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) de 12/2019 a 08/2022, trabalhando com a resistência de 47 genótipos de Coffea canephora ao parasitismo por M. paranaensis e M. exigua, sob orientação do professor Antônio Fernando de Souza. Fui indicada ao 19º Prêmio CNPq - Destaque IC, na categoria Bolsista de Iniciação Científica: Ciências da Vida. Atualmente sou aluna do mestrado em Fitopatologia (Capes 7) pela Universidade Federal de Viçosa - Campus Viçosa, e atuo no Laboratório de Controle Biológico de Fitonematoides (BIONEMA), dentro do Instituto de Biotecnologia Aplicada à Agropecuária (BIOAGRO), sob orientação do professor Leandro Grassi de Freitas.\n\n\n\n\n\n\n\n\n\n\nSobre esse site\nA proposta desse website é disponibilizar as aulas que foram ministradas na disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, da Universidade Federal de Viçosa, pelo professor Emerson Medeiros Del Ponte.\nEspero que aproveite o conteúdo!!"
  }
]